{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4b21fe2-0038-4875-9aa5-7480519c7a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 32] Le processus ne peut pas accéder au fichier car ce fichier est utilisé par un autre processus: 'c:\\\\users\\\\talelbm\\\\appdata\\\\local\\\\anaconda3\\\\lib\\\\site-packages\\\\saspy\\\\java\\\\iomclient\\\\log4j-1.2-api-2.12.4.jar'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U --quiet langchain langgraph langchain_google_genai\n",
    "%pip install -U --quiet saspy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeb9a227-e221-4ba6-9ba2-eb12593744da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import math\n",
    "import os\n",
    "import getpass\n",
    "import re\n",
    "from collections import deque\n",
    "from typing import Optional, Dict, Any, List, Tuple\n",
    "from typing_extensions import TypedDict\n",
    "import pandas as pd\n",
    "from gradio_client import Client\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "import google.generativeai as genai\n",
    "from pydantic import BaseModel, Field\n",
    "import logging\n",
    "import saspy\n",
    "import json\n",
    "# Constants\n",
    "END = \"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28030c1d-e4fc-4419-b9cf-3e373aa794b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "genai.configure(api_key=\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "436c7dfa-970a-4ee1-b099-71f97dc6b523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "GOOGLE_API_KEY ········\n"
     ]
    }
   ],
   "source": [
    "def _set_if_undefined(var: str) -> None:\n",
    "    \"\"\"Set environment variable if not already defined.\"\"\"\n",
    "    if os.environ.get(var):\n",
    "        return\n",
    "    os.environ[var] = getpass.getpass(var)\n",
    "\n",
    "_set_if_undefined(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "846d0b34-1a3a-42c1-a717-4ee5e174289d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"\"\"%(asctime)s - %(levelname)s - %(message)s\n",
    "-------------------------------------------\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0118aa83-4531-4b17-b037-c0b1bfe05c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    metadata_file_path = 'metadata_dict.json'  # Assuming the file is in the same directory\n",
    "    with open(metadata_file_path, 'r', encoding='utf-8') as f:\n",
    "        metadata_dict = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    logging.error(f\"Error: Metadata file not found at {metadata_file_path}\")\n",
    "    raise\n",
    "except json.JSONDecodeError:\n",
    "    logging.error(f\"Error: Invalid JSON format in {metadata_file_path}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a857508-0c9e-4a41-8f11-99a80e9e602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    sas = saspy.SASsession(cfgname='iomwin', cfgfile='sascfg.py')\n",
    "    logging.info(\"SAS session initialized successfully.\")\n",
    "except Exception as e:\n",
    "    logging.error(f\"Error initializing SAS session: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5643d8b6-4ca6-41d2-90e5-caa75fcf868f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetadataVerifier:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def verify_metadata(self, metadata: str, question: str, original_metadata: dict) -> tuple[bool, str]:\n",
    "        logging.info(\"Verifying metadata...\")\n",
    "        verification_prompt = f\"\"\"Act as a critical data analyst reviewing metadata selection. \n",
    "Verify if the selected metadata is contains all the sufficient and necessary databases and columns for answering the query. do not go further than that.\n",
    "if the database is sufficient to answer the query, approve it.\n",
    "\n",
    "Question: {question}\n",
    "Selected Metadata (to be analyzed carefully):\n",
    "{metadata}\n",
    "\n",
    "Complete Available Metadata (to be analyzed carefully):\n",
    "{original_metadata}\n",
    "\n",
    "Check for these specific issues:\n",
    "1. Missing Essential Columns:\n",
    "   <redacted for privacy reasons>\n",
    "\n",
    "2. Completeness Check:\n",
    "   - All columns necessary for the query's calculations\n",
    "   - All columns needed for filtering conditions\n",
    "   - All columns needed for grouping or aggregation\n",
    "   - All columns needed for the final output\n",
    "\n",
    "3. Business Rules Verification:\n",
    "   <redacted for privacy reasons>\n",
    "\n",
    "Respond with a string containing:\n",
    "    approved: boolean (\"approved: True\" or \"approved : False\"),\n",
    "    issues: [list of specific issues found, strings with \"...\" format],\n",
    "    missing columns: [list of essential missing columns, strings with \"...\" format],\n",
    "    suggestions: [specific suggestions for improvement, strings with \"...\" format],\n",
    "    criticism: \"detailed explanation of why the metadata is or isn't optimal\"\n",
    "\"\"\"\n",
    "        try:\n",
    "            response = self.model.generate_content(verification_prompt)\n",
    "            logging.info(\"Metadata verification completed.\")\n",
    "            return \"approved: True\" in response.text, response.text\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during metadata verification: {e}\")\n",
    "            return False, str(e)\n",
    "\n",
    "class CachedMetadata:\n",
    "    _instance = None\n",
    "\n",
    "    def __init__(self, question, metadata_dict):\n",
    "        if CachedMetadata._instance is not None:\n",
    "            logging.warning(\"Attempted to create a new instance of Singleton CachedMetadata.\")\n",
    "            raise Exception(\"This class is a singleton!\")\n",
    "\n",
    "        self.model_gemini = genai.GenerativeModel(\"gemini-2.0-flash-exp\")\n",
    "        self.question = question\n",
    "        self.metadata_dict = metadata_dict\n",
    "        self._metadata = None\n",
    "        self._verifier = MetadataVerifier(self.model_gemini)\n",
    "        self._generate_metadata()\n",
    "\n",
    "    @classmethod\n",
    "    def get_instance(cls, question=None, metadata_dict=None):\n",
    "        if cls._instance is None:\n",
    "            if question is None or metadata_dict is None:\n",
    "                logging.error(\"Metadata dictionary and question must be provided for the first initialization.\")\n",
    "                raise ValueError(\n",
    "                    \"Metadata dictionary and question must be provided for the first initialization.\")\n",
    "            logging.info(\"Creating new instance of CachedMetadata.\")\n",
    "            cls._instance = CachedMetadata(question, metadata_dict)\n",
    "        else:\n",
    "            logging.info(\"Returning existing instance of CachedMetadata.\")\n",
    "        return cls._instance\n",
    "\n",
    "    def _generate_metadata(self):\n",
    "        logging.info(\"Generating metadata...\")\n",
    "        prompt = f\"\"\"Act as an expert data analyst. Given a query and a database's metadata, identify the smallest set of databases \n",
    "        and columns necessary to answer the query accurately. Ensure that only the essential databases and columns are included, and \n",
    "        consider any required joins or relationships between tables. \n",
    "        Follow these specific rules:\n",
    "        - give back a string in this format : \n",
    "        \"\"\n",
    "        relevant_database1 : relevant_database1_description\n",
    "            relevant_column11 : relevant_column11_type\n",
    "                                relevant_column11_description\n",
    "                                relevant_column11_values (if they exist)\n",
    "            ...\n",
    "        \"\"\n",
    "        \n",
    "        <redacted for privacy reasons>\n",
    "        \n",
    "        Provide the selected subset of metadata as a string, including only the necessary databases and their associated columns, without any additional explanations.\"\n",
    "        Here is the question: {self.question}\n",
    "        Here is the metadata: {self.metadata_dict}\"\"\"\n",
    "\n",
    "        try:\n",
    "            response = self.model_gemini.generate_content(prompt)\n",
    "            self._metadata = response.text\n",
    "            logging.info(\"Metadata generated.\")\n",
    "\n",
    "            # Verify metadata immediately\n",
    "            is_approved, verification_result = self._verifier.verify_metadata(\n",
    "                self._metadata, self.question, self.metadata_dict\n",
    "            )\n",
    "            if not is_approved:\n",
    "                logging.warning(\"Initial metadata not approved. Regenerating...\")\n",
    "                self._regenerate_metadata(verification_result)\n",
    "            return self._metadata\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during metadata generation: {e}\")\n",
    "            raise\n",
    "\n",
    "    def _regenerate_metadata(self, verification_result):\n",
    "        logging.info(\"Regenerating metadata...\")\n",
    "        regeneration_prompt = f\"\"\"Previous metadata selection was inadequate. Please regenerate the metadata selection addressing these issues:\n",
    "        task:\n",
    "        Act as an expert data analyst. Given a query and a database's metadata, identify the smallest set of databases \n",
    "        and columns necessary to answer the query accurately. Ensure that only the essential databases and columns are included, and \n",
    "        consider any required joins or relationships between tables. \n",
    "        Follow these specific rules:\n",
    "        - give back a string in this format : \n",
    "        \"\"\n",
    "        relevant_database1 : relevant_database1_description\n",
    "            relevant_column11 : relevant_column11_type\n",
    "                                relevant_column11_description\n",
    "                                relevant_column11_values (if they exist)\n",
    "            ...\n",
    "        \"\"\n",
    "        <redacted for privacy reasons>\n",
    "        \n",
    "        Provide the selected subset of metadata as a string, including only the necessary databases and their associated columns, without any additional explanations.\n",
    "        The old response:\n",
    "        {self._metadata}\n",
    "        The full critique:\n",
    "        {verification_result}\n",
    "\n",
    "        Original question: {self.question}\n",
    "        Available metadata: {self.metadata_dict}\"\"\"\n",
    "        try:\n",
    "            response = self.model_gemini.generate_content(regeneration_prompt)\n",
    "            self._metadata = response.text\n",
    "            logging.info(\"Metadata regenerated.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during metadata regeneration: {e}\")\n",
    "            raise\n",
    "\n",
    "    def get_metadata(self):\n",
    "        return self._metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2639e0ae-4368-482b-abd2-f96b31deec0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Utility Functions ---\n",
    "def execute_sas_code(sas_code: str) -> str:\n",
    "    \"\"\"Execute SAS code and return log.\"\"\"\n",
    "    logging.info(\"Executing SAS code...\")\n",
    "    try:\n",
    "        result = sas.submit(sas_code)\n",
    "        logging.info(\"SAS code executed. Returning log.\")\n",
    "        return result['LOG']\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error executing SAS code: {e}\")\n",
    "        return str(e)\n",
    "\n",
    "def extract_data(sas_code: str, client) -> None:\n",
    "    \"\"\"Execute SAS code and save results to Excel.\"\"\"\n",
    "    logging.info(\"Extracting data...\")\n",
    "    try:\n",
    "        sas.submit(sas_code)\n",
    "        # Assuming 'client' is defined globally or passed as a parameter\n",
    "        df_name_result = client.predict(\n",
    "            query=f\"Extract final dataframe name from, dont include 'WORK.', just the raw name:\\n{sas_code}\",\n",
    "            api_name=\"/generation_code\"\n",
    "        )\n",
    "\n",
    "        if df_name_result:\n",
    "            df_name = df_name_result[0]\n",
    "            df = sas.sd2df(df_name)\n",
    "            if not df.empty:\n",
    "                excel_file = f\"{df_name}.xlsx\"\n",
    "                df.to_excel(excel_file, index=False)\n",
    "                logging.info(f\"Data extracted to {excel_file}\")\n",
    "            else:\n",
    "                logging.warning(f\"Dataframe {df_name} is empty.\")\n",
    "        else:\n",
    "            logging.warning(\"Could not determine dataframe name for extraction.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error during data extraction: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6e6cb8f-162c-419b-8b41-d13734601a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prompt Templates and System Messages ---\n",
    "def get_thinker_system_prompt(necessary_metadata):\n",
    "    return f\"\"\"\n",
    "You are StarThinker, a strategic module of the StarData AI coding agent.\n",
    "You have a basic understanding of actuary line of thinking, especially concerning automobile insurance.\n",
    "Your primary role is to analyze a given data query and devise multiple, distinct strategies for answering it using SAS code. You do not generate code, only high-level strategies.\n",
    "\n",
    "**Your Task:**\n",
    "\n",
    "- Given a data query and metadata, generate distinct and exhaustive strategies outlining how to approach the problem using the available data in the SAS databases.\n",
    "- Strategies should be concise (1-2 sentences each) and explore different logical paths to the solution.\n",
    "- Consider various ways to utilize the provided metadata, which includes database names, descriptions, column names, descriptions, types, and potential values.\n",
    "- Dynamically determine the appropriate number of strategies based on the complexity of the query. Stop generating new strategies if you deem them to be sufficient and exhaustive.\n",
    "- give your response in this format :\n",
    "    'strategy 1 : <details of this strategy>\\n\n",
    "    strategy 2 : <details of this strategy>\\n\n",
    "    ...'\n",
    "**Key Considerations from StarData:**\n",
    "\n",
    "<redacted for privacy reasons>\n",
    "\n",
    "**Metadata:**\n",
    "\n",
    "{necessary_metadata}\n",
    "\"\"\"\n",
    "\n",
    "def get_solver_system_prompt(necessary_metadata):\n",
    "    return f\"\"\"\n",
    "You are StarSolver, a code generation module of the StarData AI coding agent.\n",
    "You have a basic understanding of actuary line of thinking, especially concerning automobile insurance.\n",
    "You are an expert in SAS programming. Your task is to generate SAS code that accurately answers data queries based on provided strategies and metadata.\n",
    "\n",
    "**Your Task:**\n",
    "\n",
    "- Given a data query and a specific strategy, generate a complete and executable SAS code solution.\n",
    "- The code should be syntactically correct and produce the desired output based on the query and strategy.\n",
    "- Output ONLY the SAS code, without any explanations or additional text.\n",
    "- Save all new dataframes in the WORK library (temporary).\n",
    "- When doing union joins, select only relevant columns.\n",
    "- Adhere to all coding instructions and guidelines specified below.\n",
    "\n",
    "**Coding Instructions from StarData:**\n",
    "\n",
    "<redacted for privacy reasons>\n",
    "\n",
    "**Metadata:**\n",
    "\n",
    "{necessary_metadata}\n",
    "\"\"\"\n",
    "\n",
    "def get_debugger_system_prompt(necessary_metadata):\n",
    "    return f\"\"\"\n",
    "You are StarDebugger, a code refinement module of the StarData AI coding agent.\n",
    "You have a basic understanding of actuary line of thinking, especially concerning automobile insurance.\n",
    "You are an expert in SAS programming and debugging. Your task is to refine and improve SAS code solutions based on provided feedback.\n",
    "\n",
    "**Your Task:**\n",
    "\n",
    "- Given a SAS code solution, and feedback (which may include error messages, requirement shortcomings, or suggestions), generate a corrected and improved version of the code.\n",
    "- The refined code should address all issues mentioned in the feedback and produce the desired output according to the original query.\n",
    "- Output ONLY the refined SAS code, without any explanations or additional text.\n",
    "\n",
    "**Coding and Debugging Instructions from StarData:**\n",
    "<redacted for privacy reasons>\n",
    "**Metadata:**\n",
    "\n",
    "{necessary_metadata}\n",
    "\"\"\"\n",
    "\n",
    "def get_critic_system_prompt(necessary_metadata):\n",
    "    return f\"\"\"\n",
    "You are StarCritic, a solution evaluator module of the StarData AI coding agent.\n",
    "You have a basic understanding of actuary line of thinking, especially concerning automobile insurance.\n",
    "You are an expert in SAS programming and analysis. Your task is to evaluate SAS code solutions generated by the Solver agent, provide feedback, and assess their suitability for refinement or acceptance.\n",
    "\n",
    "**Your Task:**\n",
    "\n",
    "- Given a SAS code solution, its corresponding strategy, and the original query, evaluate the solution's correctness, adherence to the strategy, and overall quality.\n",
    "- Provide a numerical score (critic_score) that reflects the solution's quality and potential for improvement.\n",
    "- Generate specific feedback (feedback) that identifies errors, missing requirements, and areas for improvement.\n",
    "- Determine whether the solution should be refined, aborted, or accepted based on your evaluation.\n",
    "\n",
    "**Evaluation Criteria:**\n",
    "\n",
    "- **Correctness:** Does the code execute without errors? Does it produce the expected output for visible test cases?\n",
    "- **Strategy Adherence:** Does the code effectively implement the given strategy? Does it logically follow the strategy and use appropriate data structures and algorithms?\n",
    "- **Robustness:** Is the solution likely to be correct for unseen test cases? Does it handle potential edge cases and demonstrate a general understanding of the problem?\n",
    "- **Requirements Fulfillment:** Does the code meet all the requirements stated in the original query? Are there any missing functionalities or discrepancies?\n",
    "\n",
    "**Decision Logic:**\n",
    "\n",
    "- **Refine:** If the solution has errors, fails to meet requirements, or does not fully adhere to the strategy, it should be refined.\n",
    "- **Abort:** If the solution has major flaws, scores very low on the evaluation criteria, or is unlikely to be improved with further refinement, it should be aborted.\n",
    "- **Accept:** If the solution passes all visible test cases, adheres to the strategy, meets all requirements, and is deemed robust, it should be accepted as the final solution.\n",
    "\n",
    "**Additional Instructions:**\n",
    "\n",
    "- Consider the provided metadata when evaluating the solution's correctness and requirements fulfillment.\n",
    "- Be specific in your feedback, pointing out the exact lines of code or functionalities that need improvement.\n",
    "- Use a combination of numerical scores and qualitative feedback to provide a comprehensive evaluation.\n",
    "- When dealing with the GOUVERNORAT COLUMN, automatically make these changes: \"LE KEF\" to \"KEF\", \"MEHDIA\" to \"MAHDIA\", and \"MANOUBA\" to \"MANNOUBA\".\n",
    "- A sinistre is an accident, identified by a key and associated with its police. A sinistre can happen in year x and not get reported until later years. So when looking for a sinistre that happened in year x, you need to look for all the vue_sinistres_y where y>=x. RADHOUAN.VUE_SINISTRE is basically vue_sinistre_2024.\n",
    "- When asked about characteristics of a sinistre that don't exist in the vue_sinistre database (e.g., gouvernorat or classe bm of the associated policy), you have to look for these details in the dataframes associated with the policies and make the due join operations.\n",
    "- When asked about a history of a sinistre, you need to first verify if it exists in RADHOUAN.VUE_HIST_SINISTRE.\n",
    "- When making unions make sure that the columns of the same name are of similar type too.\n",
    "- When asked for filtering by 'Défense' or 'Recours' automatically filter by column TYPE_DOSSIER_AFIN and try to find the lines that contain 'Défense' or 'Recours'\n",
    "- When asked for calculation that use reglements columns, always use reglements afin, same with reserve, use reserve_afin unless explicitly stated otherwise in the query.\n",
    "\n",
    "**Metadata:**\n",
    "\n",
    "{necessary_metadata}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ce92129-62ab-45d1-b9c9-d036775ff50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Agent Classes ---\n",
    "class Thinker:\n",
    "    def __init__(self, llm, necessary_metadata):\n",
    "        self.llm = llm\n",
    "        self.necessary_metadata = necessary_metadata\n",
    "        self.strategies_cache: Dict[str, List[str]] = {}\n",
    "        self.reflections_cache: Dict[Tuple[str, str, str, str], List[str]] = {}\n",
    "\n",
    "    def generate_strategies(self, question: str, max_strategies: int = 5, previous_strategies: List[str] = None) -> List[str]:\n",
    "        \"\"\"Generates multiple strategies for solving the coding problem autoregressively.\"\"\"\n",
    "        logging.info(f\"Generating strategies for question: {question}\")\n",
    "        if question in self.strategies_cache:\n",
    "            logging.info(f\"Using cached strategies for question: {question}\")\n",
    "            return self.strategies_cache[question]\n",
    "\n",
    "        strategies = []\n",
    "        \n",
    "        if previous_strategies is not None:\n",
    "            strategies = previous_strategies\n",
    "\n",
    "        for i in range(max_strategies):\n",
    "            prompt = self._build_strategy_prompt(question, strategies)\n",
    "            try:\n",
    "                response = (prompt | self.llm | StrOutputParser()).invoke({\n",
    "                    \"question\": question,\n",
    "                    \"necessary_metadata\": self.necessary_metadata,\n",
    "                    \"previous_strategies\": \"\\n\".join(strategies)\n",
    "                })\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error during strategy generation: {e}\")\n",
    "                break\n",
    "\n",
    "            new_strategy = self._extract_strategy(response)\n",
    "            if not new_strategy or new_strategy.lower() == \"no further strategies.\":\n",
    "                logging.info(\"No further strategies generated.\")\n",
    "                break\n",
    "\n",
    "            strategies.append(new_strategy)\n",
    "            logging.info(f\"Generated strategy {i+1}: {new_strategy}\")\n",
    "\n",
    "        self.strategies_cache[question] = strategies\n",
    "        return strategies\n",
    "\n",
    "    def _build_strategy_prompt(self, question: str, previous_strategies: List[str]) -> ChatPromptTemplate:\n",
    "        \"\"\"Builds the prompt for generating the next strategy.\"\"\"\n",
    "        system_prompt = get_thinker_system_prompt(self.necessary_metadata)\n",
    "\n",
    "        if previous_strategies:\n",
    "            system_prompt += \"\\n\\nPrevious Strategies:\\n\" + \"\\n\".join(\n",
    "                [f\"{i+1}. {strategy}\" for i, strategy in enumerate(previous_strategies)]\n",
    "            )\n",
    "        system_prompt += \"\\n\\nGenerate the next strategy, or write 'No further strategies.' if no further strategies can be generated.\"\n",
    "\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", system_prompt),\n",
    "            (\"user\", f\"Question: {question}\\nStrategy:\")\n",
    "        ])\n",
    "        return prompt\n",
    "\n",
    "    def _extract_strategy(self, response: str) -> str:\n",
    "        \"\"\"Extracts a strategy from the LLM's response.\"\"\"\n",
    "        # Use regex to find the strategy after 'strategy x :'\n",
    "        match = re.search(r\"strategy \\d+ : (.*)\", response, re.IGNORECASE)\n",
    "        if match:\n",
    "            return match.group(1).strip()\n",
    "        else:\n",
    "            return \"\"\n",
    "\n",
    "    def generate_reflections(self, question: str, solution: str, feedback: str, log: str, strategy: str,\n",
    "                             num_reflections: int = 3) -> List[str]:\n",
    "        \"\"\"Generates reflections on the code autoregressively.\"\"\"\n",
    "        logging.info(f\"Generating reflections for question: {question}\")\n",
    "        cache_key = (question, solution, feedback, log)\n",
    "        if cache_key in self.reflections_cache:\n",
    "            logging.info(f\"Using cached reflections for question: {question}\")\n",
    "            return self.reflections_cache[cache_key]\n",
    "\n",
    "        reflections = []\n",
    "        for _ in range(num_reflections):\n",
    "            prompt = self._build_reflection_prompt(question, solution, feedback, log, strategy, reflections)\n",
    "            try:\n",
    "                response = (prompt | self.llm | StrOutputParser()).invoke({\n",
    "                    \"question\": question,\n",
    "                    \"solution\": solution,\n",
    "                    \"feedback\": feedback,\n",
    "                    \"log\": log,\n",
    "                    \"strategy\": strategy,\n",
    "                    \"necessary_metadata\": self.necessary_metadata,\n",
    "                    \"previous_reflections\": \"\\n\".join(reflections)\n",
    "                })\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error during reflection generation: {e}\")\n",
    "                break\n",
    "\n",
    "            new_reflection = response.strip()\n",
    "            if not new_reflection or new_reflection.lower() == \"no further reflections.\":\n",
    "                logging.info(\"No further reflections generated.\")\n",
    "                break\n",
    "            reflections.append(new_reflection)\n",
    "            logging.info(f\"Generated reflection: {new_reflection}\")\n",
    "\n",
    "        self.reflections_cache[cache_key] = reflections\n",
    "        return reflections\n",
    "\n",
    "    def _build_reflection_prompt(self, question: str, solution: str, feedback: str, log: str, strategy: str,\n",
    "                                 previous_reflections: List[str]) -> ChatPromptTemplate:\n",
    "        \"\"\"Builds the prompt for generating the next reflection.\"\"\"\n",
    "        system_prompt = get_thinker_system_prompt(self.necessary_metadata)\n",
    "        system_prompt += f\"\\n\\nStrategy used: {strategy}\"\n",
    "        system_prompt += \"\\n\\nYour task is to generate reflections on the following SAS code solution, considering the feedback and log provided. \"\n",
    "        system_prompt += \"Reflections should be concise and focus on identifying areas for improvement or issues in the code.\"\n",
    "\n",
    "        if previous_reflections:\n",
    "            system_prompt += \"\\n\\nPrevious Reflections:\\n\" + \"\\n\".join(\n",
    "                [f\"{i+1}. {reflection}\" for i, reflection in enumerate(previous_reflections)]\n",
    "            )\n",
    "            system_prompt += \"\\n\\nGenerate the next reflection, or write 'No further reflections.' if no further reflections are needed\"\n",
    "\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", system_prompt),\n",
    "            (\"user\", f\"Given the question: '{question}', the strategy: '{strategy}', the following SAS code solution: \\n\"\n",
    "                     f\"```sas\\n{solution}\\n```\\n\"\n",
    "                     f\"and the feedback from the Critic: '{feedback}',\\n\"\n",
    "                     f\"and the log from the code execution : '{log}', \\n\"\n",
    "                     f\"please generate reflections to guide the code refinement process.\")\n",
    "        ])\n",
    "        return prompt\n",
    "\n",
    "class Solver:\n",
    "    def __init__(self, llm, necessary_metadata):\n",
    "        self.llm = llm\n",
    "        self.necessary_metadata = necessary_metadata\n",
    "        self.solutions_cache: Dict[Tuple[str, str], str] = {}\n",
    "\n",
    "    def generate_solution(self, question: str, strategy: str) -> str:\n",
    "        \"\"\"Generates an initial SAS code solution based on the given strategy.\"\"\"\n",
    "        logging.info(f\"Generating solution for question: {question} with strategy: {strategy}\")\n",
    "        cache_key = (question, strategy)\n",
    "        if cache_key in self.solutions_cache:\n",
    "            logging.info(f\"Using cached solution for question: {question} and strategy: {strategy}\")\n",
    "            return self.solutions_cache[cache_key]\n",
    "\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", get_solver_system_prompt(self.necessary_metadata)),\n",
    "            (\"user\", f\"Given the strategy: '{strategy}', please write SAS code to answer this question: {question}\")\n",
    "        ])\n",
    "        try:\n",
    "            response = (prompt | self.llm | StrOutputParser()).invoke({\n",
    "                \"question\": question,\n",
    "                \"strategy\": strategy,\n",
    "                \"necessary_metadata\": self.necessary_metadata\n",
    "            })\n",
    "            solution = self._extract_code(response)\n",
    "            logging.info(f\"Generated solution:\\n{solution}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during solution generation: {e}\")\n",
    "            solution = \"\"\n",
    "\n",
    "        self.solutions_cache[cache_key] = solution\n",
    "        return solution\n",
    "\n",
    "    def _extract_code(self, response: str) -> str:\n",
    "        \"\"\"Extracts the SAS code from the LLM's response.\"\"\"\n",
    "        return response.strip()\n",
    "\n",
    "class Debugger:\n",
    "    def __init__(self, llm, necessary_metadata):\n",
    "        self.llm = llm\n",
    "        self.necessary_metadata = necessary_metadata\n",
    "        self.debugged_solutions_cache: Dict[Tuple[str, str, str], str] = {}\n",
    "\n",
    "    def generate_refinement(self, question: str, solution: str, reflections: str) -> str:\n",
    "        \"\"\"Refines the given SAS code solution based on reflections.\"\"\"\n",
    "        logging.info(f\"Generating refinement for question: {question}\")\n",
    "        cache_key = (question, solution, reflections)\n",
    "        if cache_key in self.debugged_solutions_cache:\n",
    "            logging.info(f\"Using cached refined solution for question: {question}\")\n",
    "            return self.debugged_solutions_cache[cache_key]\n",
    "\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", get_debugger_system_prompt(self.necessary_metadata)),\n",
    "            (\"user\",\n",
    "             f\"Given the reflections: '{reflections}', please refine the following SAS code:\\n```sas\\n{solution}\\n```\")\n",
    "        ])\n",
    "        try:\n",
    "            response = (prompt | self.llm | StrOutputParser()).invoke({\n",
    "                \"question\": question,\n",
    "                \"solution\": solution,\n",
    "                \"reflections\": reflections,\n",
    "                \"necessary_metadata\": self.necessary_metadata\n",
    "            })\n",
    "            refined_solution = self._extract_code(response)\n",
    "            logging.info(f\"Generated refined solution:\\n{refined_solution}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during refinement generation: {e}\")\n",
    "            refined_solution = \"\"\n",
    "\n",
    "        self.debugged_solutions_cache[cache_key] = refined_solution\n",
    "        return refined_solution\n",
    "\n",
    "    def _extract_code(self, response: str) -> str:\n",
    "        \"\"\"Extracts the SAS code from the LLM's response.\"\"\"\n",
    "        return response.strip()\n",
    "\n",
    "class Critic:\n",
    "    def __init__(self, llm, client, necessary_metadata, config: Dict):\n",
    "        self.llm = llm\n",
    "        self.client = client\n",
    "        self.necessary_metadata = necessary_metadata\n",
    "        self.evaluation_cache = {}\n",
    "        self.config = config\n",
    "\n",
    "    def evaluate_solution(self, question: str, solution: str, strategy: str) -> Tuple[str, float, str]:\n",
    "        \"\"\"Evaluates the generated solution, provides feedback, and assigns a numerical score.\"\"\"\n",
    "        logging.info(f\"Evaluating solution for question: {question}\")\n",
    "        cache_key = (question, solution, strategy)\n",
    "        if cache_key in self.evaluation_cache:\n",
    "            logging.info(f\"Using cached evaluation for question: {question}\")\n",
    "            return self.evaluation_cache[cache_key]\n",
    "            \n",
    "        if \"```sas\" in solution:\n",
    "            start_index = solution.find(\"```sas\") + 6  # +6 to skip \"```sas\"\n",
    "            end_index = solution.find(\"```\", start_index)\n",
    "        if end_index != -1:\n",
    "              solution = solution[start_index:end_index].strip()\n",
    "            \n",
    "        log = execute_sas_code(solution)\n",
    "        try:\n",
    "            error_reflection = self._get_error_reflection(question, solution, log)\n",
    "            requirement_reflection = self._get_requirement_reflection(question, solution, log)\n",
    "            strategy_adherence_reflection = self._get_strategy_adherence_reflection(question, solution, strategy)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during reflections generation : {e}\")\n",
    "            raise\n",
    "\n",
    "        # --- More Detailed Evaluation ---\n",
    "        evaluation = \"\"\n",
    "        critic_score = 0.0\n",
    "        feedback = \"\"\n",
    "\n",
    "        if error_reflection.error_count > 0:\n",
    "            feedback += \"Errors:\\n\"\n",
    "            feedback += f\"- {error_reflection.error_log}\\n\"\n",
    "            critic_score += self.config[\"error_weight\"]  # Use configurable weight\n",
    "            evaluation = \"Refine\"\n",
    "\n",
    "        if not requirement_reflection.requirements_met:\n",
    "            feedback += \"Missing Requirements:\\n\"\n",
    "            feedback += f\"- {requirement_reflection.missing_requirements}\\n\"\n",
    "            critic_score += self.config[\"requirement_weight\"]  # Use configurable weight\n",
    "            evaluation = \"Refine\" if evaluation != \"Refine\" else \"Refine\"\n",
    "\n",
    "        # Strategy Adherence Score\n",
    "        critic_score = (\n",
    "                            critic_score + strategy_adherence_reflection.adherence_score\n",
    "                        ) / 2 if evaluation == \"Refine\" else strategy_adherence_reflection.adherence_score\n",
    "\n",
    "        feedback += f\"Strategy Adherence: {strategy_adherence_reflection.adherence_score:.2f} - {strategy_adherence_reflection.reasoning}\\n\"\n",
    "\n",
    "        # --- Decision Logic ---\n",
    "        if error_reflection.error_count == 0 and requirement_reflection.requirements_met:\n",
    "            # Solution passes visible tests, perform verification\n",
    "            try:\n",
    "                if self.verify_solution(question, solution):\n",
    "                    evaluation = \"Accept\"\n",
    "                    critic_score = 1.0  # Perfect score if it passes verification\n",
    "                else:\n",
    "                    evaluation = \"Refine\"\n",
    "                    feedback += \"Solution passes visible tests but fails verification (potential overfitting or lack of robustness).\\n\"\n",
    "                    critic_score = self.config[\"verification_fail_score\"]  # Use configurable score\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error during solution verification : {e}\")\n",
    "                evaluation = \"Refine\"\n",
    "                feedback += \"Solution passes visible tests but fails verification (potential overfitting or lack of robustness).\\n\"\n",
    "                critic_score = self.config[\"verification_fail_score\"]\n",
    "        elif critic_score < self.config[\"abort_threshold\"]:  # Use configurable threshold\n",
    "            evaluation = \"Abort\"\n",
    "\n",
    "        logging.info(f\"Evaluation: {evaluation}, Critic Score: {critic_score}, Feedback: {feedback}\")\n",
    "        self.evaluation_cache[cache_key] = (evaluation, critic_score, feedback)\n",
    "        return evaluation, critic_score, feedback\n",
    "\n",
    "    def verify_solution(self, question: str, solution: str) -> bool:\n",
    "        \"\"\"Verifies if a solution that passes visible tests is robust and generalizable.\"\"\"\n",
    "        logging.info(f\"Verifying solution for question: {question}\")\n",
    "        verification_prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", get_critic_system_prompt(self.necessary_metadata)),\n",
    "            (\"user\", f\"\"\"\n",
    "        We have a SAS code solution that passes all visible test cases for the query: '{question}'.\n",
    "        ```sas\n",
    "        {solution}\n",
    "        ```\n",
    "        Your task is to assess whether this solution is likely to be correct for unseen test cases as well. \n",
    "        Consider the following:\n",
    "        - Does the code seem overly tailored to the specific visible test cases, or does it demonstrate a general understanding of the problem?\n",
    "        - Are there any potential edge cases or scenarios not covered by the visible tests that the code might fail on?\n",
    "\n",
    "        Answer with 'True' if the solution is likely to be correct for unseen test cases, and 'False' otherwise. Provide a brief explanation for your assessment.\n",
    "        \"\"\")\n",
    "    ])\n",
    "        try:\n",
    "            response = (verification_prompt | self.llm | StrOutputParser()).invoke({\n",
    "            \"question\": question,\n",
    "            \"solution\": solution,\n",
    "            \"necessary_metadata\": self.necessary_metadata\n",
    "        })\n",
    "\n",
    "            logging.info(f\"Raw verification response: {response}\")  # Log the raw response\n",
    "\n",
    "            # Normalize the response to handle variations (e.g., \"True.\", \"True \", \"TRUE\")\n",
    "            cleaned_response = response.strip().lower() \n",
    "\n",
    "            logging.info(f\"Cleaned verification response: {cleaned_response}\") # Log the cleaned response\n",
    "\n",
    "            if \"true\" in cleaned_response:\n",
    "                logging.info(\"Solution verification successful.\")\n",
    "                return True\n",
    "            else:\n",
    "                logging.warning(f\"Solution verification failed: {response}\")\n",
    "                return False\n",
    "\n",
    "        except Exception as e:\n",
    "             logging.error(f\"Error during solution verification: {e}\")\n",
    "             return False\n",
    "\n",
    "    def _get_error_reflection(self, query: str, sas_code: str, log: str) -> \"ErrorReflection\":\n",
    "        \"\"\"\n",
    "        Identifies errors in the SAS log and provides an ErrorReflection.\n",
    "        Now also tries to categorize the error.\n",
    "        \"\"\"\n",
    "        logging.info(\"Getting error reflection...\")\n",
    "        parser = PydanticOutputParser(pydantic_object=ErrorReflection)\n",
    "\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\",\n",
    "             \"You are a helpful assistant that identifies and categorizes errors in SAS code execution logs. {format_instructions}\"),\n",
    "            (\"user\", \"Query: {query}\\nCode:\\n```sas\\n{sas_code}\\n```\\nLog:\\n{log}\")\n",
    "        ])\n",
    "        try:\n",
    "            response = (prompt | self.llm | parser).invoke({\n",
    "                \"query\": query,\n",
    "                \"sas_code\": sas_code,\n",
    "                \"log\": log,\n",
    "                \"format_instructions\": parser.get_format_instructions()\n",
    "            })\n",
    "            logging.info(\n",
    "                f\"Error reflection: Error Count: {response.error_count}, Error Log: {response.error_log}, Error Category: {response.error_category}\")\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during error reflection generation : {e}\")\n",
    "            raise\n",
    "\n",
    "    def _get_requirement_reflection(self, query: str, sas_code: str, log: str) -> \"RequirementReflection\":\n",
    "        \"\"\"\n",
    "        Determines whether the SAS code meets the requirements of the original query and provides a RequirementReflection.\n",
    "        Now uses a PydanticOutputParser for structured output.\n",
    "        \"\"\"\n",
    "        logging.info(\"Getting requirement reflection...\")\n",
    "        parser = PydanticOutputParser(pydantic_object=RequirementReflection)\n",
    "\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", f\"\"\"\n",
    "            You are a helpful assistant that identifies missing requirements in SAS code.\n",
    "            Use the metadata to understand the database and ensure the requirements are aligned with the database's structure.\n",
    "            {{format_instructions}}\n",
    "            metadata : {self.necessary_metadata}\"\"\"),\n",
    "            (\"user\", f\"\"\"\n",
    "            Original Query: {query}\n",
    "            Generated SAS Code:\n",
    "            ```sas\n",
    "            {sas_code}\n",
    "            ```\n",
    "            Does the SAS code fulfill all requirements stated in the original query?\n",
    "            Answer with 'True' if everything is generally satisfying to the average user, only give back \"False\" if there flagrant error of totally not understanding the query.\n",
    "            \"\"\")\n",
    "        ])\n",
    "        try:\n",
    "            response = (prompt | self.llm | parser).invoke({\n",
    "                \"query\": query,\n",
    "                \"sas_code\": sas_code,\n",
    "                \"necessary_metadata\": self.necessary_metadata,\n",
    "                \"format_instructions\": parser.get_format_instructions()\n",
    "            })\n",
    "            logging.info(\n",
    "                f\"Requirement reflection: Missing Requirements: {response.missing_requirements}, Requirements Met: {response.requirements_met}\")\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during requirement reflection generation : {e}\")\n",
    "            raise\n",
    "\n",
    "    def _get_strategy_adherence_reflection(self, query: str, sas_code: str,\n",
    "                                            strategy: str) -> \"StrategyAdherenceReflection\":\n",
    "        \"\"\"\n",
    "        Evaluates the adherence of the SAS code to the given strategy and provides a StrategyAdherenceReflection.\n",
    "        Uses a PydanticOutputParser for structured output, including a numerical score.\n",
    "        \"\"\"\n",
    "        logging.info(\"Getting strategy adherence reflection...\")\n",
    "        parser = PydanticOutputParser(pydantic_object=StrategyAdherenceReflection)\n",
    "\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", f\"\"\"\n",
    "            You are a helpful assistant that evaluates the adherence of SAS code to a given strategy.\n",
    "            Use the metadata to understand the database and ensure the code aligns with the strategy and the database's structure.\n",
    "            {{format_instructions}}\n",
    "            metadata : {self.necessary_metadata}\n",
    "            \"\"\"),\n",
    "            (\"user\", f\"\"\"\n",
    "            Original Query: {query}\n",
    "            Strategy: {strategy}\n",
    "            Generated SAS Code:\n",
    "            ```sas\n",
    "            {sas_code}\n",
    "            ```\n",
    "            Assess the adherence of the SAS code to the given strategy. Consider:\n",
    "            1. How well does the code logically follow the strategy?\n",
    "            2. Does the code use appropriate data structures and algorithms as suggested by the strategy?\n",
    "            3. Are there any deviations from the strategy, and if so, are they justified?\n",
    "            Provide a numerical adherence score between 0 and 1, where 1 represents perfect adherence and 0 represents no adherence.\n",
    "            \"\"\")\n",
    "        ])\n",
    "\n",
    "        try:\n",
    "            response = (prompt | self.llm | parser).invoke({\n",
    "                \"query\": query,\n",
    "                \"sas_code\": sas_code,\n",
    "                \"strategy\": strategy,\n",
    "                \"necessary_metadata\": self.necessary_metadata,\n",
    "                \"format_instructions\": parser.get_format_instructions()\n",
    "            })\n",
    "            logging.info(\n",
    "                f\"Strategy adherence reflection: Adherence Score: {response.adherence_score}, Reasoning: {response.reasoning}\")\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during strategy adherence reflection generation: {e}\")\n",
    "            raise\n",
    "\n",
    "class ErrorReflection(BaseModel):\n",
    "    error_count: int = Field(description=\"Number of errors in SAS log\")\n",
    "    error_log: str = Field(description=\"Portion of the log that contains error messages\")\n",
    "    error_category: str = Field(..., description=\"Category of the error (e.g., syntax, runtime, logical)\")\n",
    "\n",
    "class RequirementReflection(BaseModel):\n",
    "    missing_requirements: str = Field(description=\"Requirements not met in the code\")\n",
    "    requirements_met: bool = Field(description=\"Whether all requirements are met\")\n",
    "\n",
    "class StrategyAdherenceReflection(BaseModel):\n",
    "    adherence_score: float = Field(...,\n",
    "                                   description=\"Numerical score between 0 and 1 representing adherence to the strategy\")\n",
    "    reasoning: str = Field(..., description=\"Explanation of the adherence score, including any deviations from the strategy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45407faa-61a1-44e0-b188-cbb205f05a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Node and TreeState ---\n",
    "class Node:\n",
    "    def __init__(\n",
    "            self,\n",
    "            strategy: str,\n",
    "            solution: str,\n",
    "            evaluation: str,\n",
    "            config: Dict,\n",
    "            critic_score: float = 0,\n",
    "            parent: Optional[\"Node\"] = None,\n",
    "            question: Optional[str] = None,\n",
    "\n",
    "    ):\n",
    "        self.strategy = strategy\n",
    "        self.solution = solution\n",
    "        self.parent = parent\n",
    "        self.children = []\n",
    "        self.evaluation = evaluation\n",
    "        self.visits = 0\n",
    "        self.value = 0\n",
    "        self.critic_score = critic_score\n",
    "        self.score = 0\n",
    "        self.depth = parent.depth + 1 if parent is not None else 1\n",
    "        self.question = question if question is not None else (parent.question if parent is not None else None)\n",
    "        self.config = config\n",
    "        if self.evaluation == \"Accept\":\n",
    "            self.backpropagate(1, self.config)\n",
    "        else:\n",
    "            self.backpropagate(0, self.config)\n",
    "\n",
    "    def calculate_score(self, config: Dict) -> float:\n",
    "        \"\"\"Calculates the node's score based on execution results and Critic's evaluation.\"\"\"\n",
    "        logging.info(f\"Calculating score for node with strategy: {self.strategy}\")\n",
    "        execution_score = 0\n",
    "\n",
    "        if self.solution:  # Only calculate if a solution exists\n",
    "            log = execute_sas_code(self.solution)\n",
    "            num_tests = 0\n",
    "            passed_tests = 0\n",
    "\n",
    "            # Example: Simple pass/fail scoring (adapt based on your test case format)\n",
    "            for line in log.splitlines():\n",
    "                if \"passed:\" in line.lower():\n",
    "                    num_tests += 1\n",
    "                    if \"true\" in line.lower():\n",
    "                        passed_tests += 1\n",
    "                if \"test ok\" in line.lower():\n",
    "                    num_tests += 1\n",
    "                    passed_tests += 1\n",
    "\n",
    "            if num_tests > 0:\n",
    "                execution_score = passed_tests / num_tests\n",
    "\n",
    "        # Combine execution score and Critic's score (weighted average)\n",
    "        # Use weights from config\n",
    "        self.score = config[\"execution_weight\"] * execution_score + config[\"critic_weight\"] * self.critic_score\n",
    "        logging.info(f\"Node score calculated: {self.score}\")\n",
    "        return self.score\n",
    "\n",
    "    def upper_confidence_bound(self, exploration_weight: float = math.sqrt(2)) -> float:\n",
    "        if self.visits == 0:\n",
    "            return float('inf')\n",
    "        exploitation = self.value / self.visits\n",
    "        exploration = math.sqrt(math.log(self.parent.visits) / self.visits)\n",
    "        return exploitation + exploration_weight * exploration\n",
    "\n",
    "    def backpropagate(self, reward: float, config: Dict) -> None:\n",
    "        \"\"\"Updates the node's value and propagates it to its ancestors.\"\"\"\n",
    "        logging.info(f\"Backpropagating reward: {reward} for node with strategy: {self.strategy}\")\n",
    "        node = self\n",
    "        while node:\n",
    "            node.visits += 1\n",
    "            node.value = (node.value * (node.visits - 1) + reward) / node.visits\n",
    "            if node.evaluation == \"Accept\":\n",
    "                node.score = 1\n",
    "            else:\n",
    "                node.calculate_score(config)  # Recalculate score during backpropagation\n",
    "            node = node.parent\n",
    "\n",
    "    def select_child(self) -> \"Node\":\n",
    "        \"\"\"Selects the best child using UCB.\"\"\"\n",
    "        logging.info(f\"Selecting child for node with strategy: {self.strategy}\")\n",
    "        best_child = None\n",
    "        best_ucb = float('-inf')\n",
    "        for child in self.children:\n",
    "            ucb = child.upper_confidence_bound()\n",
    "            if ucb > best_ucb:\n",
    "                best_ucb = ucb\n",
    "                best_child = child\n",
    "        logging.info(f\"Selected child with strategy: {best_child.strategy if best_child else 'None'}\")\n",
    "        return best_child\n",
    "\n",
    "    def is_terminal(self) -> bool:\n",
    "        return self.evaluation == \"Accept\"\n",
    "\n",
    "    def get_best_solution(self) -> \"Node\":\n",
    "        \"\"\"Retrieves the best solution from the subtree rooted at this node.\"\"\"\n",
    "        logging.info(f\"Getting best solution for node with strategy: {self.strategy}\")\n",
    "        all_nodes = [self] + self._get_all_children()\n",
    "        best_node = max(\n",
    "            all_nodes,\n",
    "            key=lambda node: (1 if node.evaluation == \"Accept\" else 0) * node.value\n",
    "        )\n",
    "        logging.info(f\"Best solution found: {best_node.solution}\")\n",
    "        return best_node\n",
    "\n",
    "    def _get_all_children(self) -> List[\"Node\"]:\n",
    "        \"\"\"Retrieves all children of this node (recursively).\"\"\"\n",
    "        all_nodes = []\n",
    "        queue = deque(self.children)\n",
    "        while queue:\n",
    "            node = queue.popleft()\n",
    "            all_nodes.append(node)\n",
    "            queue.extend(node.children)\n",
    "        return all_nodes\n",
    "\n",
    "class TreeState(TypedDict):\n",
    "    root: Optional[Node]\n",
    "    input: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc2255e5-cde3-4e9b-91d2-5da9a0aba354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Tree Expansion Functions ---\n",
    "def generate_initial_strategies(state: TreeState, llm, client, necessary_metadata, config) -> dict:\n",
    "    \"\"\"Generates initial strategies and creates the root node.\"\"\"\n",
    "    question = state[\"input\"]\n",
    "    logging.info(f\"Generating initial strategies for question: {question}\")\n",
    "    thinker = Thinker(llm, necessary_metadata)\n",
    "    solver = Solver(llm, necessary_metadata)\n",
    "    critic = Critic(llm, client, necessary_metadata, config)\n",
    "\n",
    "    # Create a dummy root node\n",
    "    root = Node(strategy=\"Root\", solution=\"\", evaluation=\"Expand\", question=question, config=config)\n",
    "\n",
    "    # Generate and evaluate strategies one by one\n",
    "    strategies = []\n",
    "    for i in range(5):  # Assuming a maximum of 5 initial strategies as before\n",
    "        \n",
    "        if i == 0 :\n",
    "            # 1. Generate a strategy\n",
    "            strategy = thinker.generate_strategies(question, 1)\n",
    "            new_strategy = strategy[0]\n",
    "        else :\n",
    "            strategy = thinker.generate_strategies(question, 1, strategies)\n",
    "            new_strategy = strategy[0]\n",
    "            \n",
    "        if not new_strategy or new_strategy.lower() == \"no further strategies.\":\n",
    "            logging.info(\"No further strategies generated.\")\n",
    "            break\n",
    "\n",
    "        strategies.append(new_strategy)\n",
    "        logging.info(f\"Generated strategy {i+1}: {new_strategy}\")\n",
    "\n",
    "        # 2. Create a child node for the new strategy\n",
    "        child_node = Node(strategy=new_strategy, solution=\"\", evaluation=\"Expand\", parent=root, question=question,\n",
    "                          config=config)\n",
    "        root.children.append(child_node)\n",
    "\n",
    "        # 3. Generate a solution for the strategy\n",
    "        solution = solver.generate_solution(question, new_strategy)\n",
    "        child_node.solution = solution  # Update the node with the solution\n",
    "\n",
    "        # 4. Evaluate the solution\n",
    "        evaluation, critic_score, feedback = critic.evaluate_solution(question, solution, new_strategy)\n",
    "        child_node.evaluation = evaluation\n",
    "        child_node.critic_score = critic_score\n",
    "        child_node.calculate_score(config)\n",
    "\n",
    "        # 5. Check if the solution is verified (\"Accept\")\n",
    "        if evaluation == \"Accept\":\n",
    "            logging.info(f\"Verified solution found for strategy: {new_strategy}. Stopping initial strategy generation.\")\n",
    "            return {**state, \"root\": root}  # Stop early\n",
    "\n",
    "    logging.info(\"Finished generating initial strategies.\")\n",
    "    return {**state, \"root\": root}\n",
    "\n",
    "def expand_tree(state: TreeState, llm, client, necessary_metadata, config: Dict, max_depth: int = 5) -> dict:\n",
    "    \"\"\"Expands the tree based on node evaluations and scores.\"\"\"\n",
    "    root = state[\"root\"]\n",
    "    question = state[\"input\"]\n",
    "\n",
    "    # Check if an \"Accept\" node already exists before expanding\n",
    "    if any(node.evaluation == \"Accept\" for node in root._get_all_children()):\n",
    "        logging.info(\"Acceptable solution already exists. Skipping expansion.\")\n",
    "        return state\n",
    "\n",
    "    logging.info(f\"Expanding tree for question: {question}\")\n",
    "    current_node = select_node_to_expand(root)\n",
    "    logging.info(f\"Selected node for expansion: {current_node.strategy}\")\n",
    "\n",
    "    solver = Solver(llm, necessary_metadata)\n",
    "    critic = Critic(llm, client, necessary_metadata, config)\n",
    "    debugger = Debugger(llm, necessary_metadata)\n",
    "    thinker = Thinker(llm, necessary_metadata)\n",
    "\n",
    "    if current_node.evaluation == \"Expand\":\n",
    "        # Generate solution and evaluate\n",
    "        logging.info(f\"Generating solution for node: {current_node.strategy}\")\n",
    "        solution = solver.generate_solution(question, current_node.strategy)\n",
    "        logging.info(f\"Evaluating solution: {solution}\")\n",
    "        evaluation, critic_score, feedback = critic.evaluate_solution(question, solution, current_node.strategy)\n",
    "\n",
    "        # Update current node and create a new node\n",
    "        current_node.solution = solution\n",
    "        current_node.evaluation = evaluation\n",
    "        current_node.critic_score = critic_score\n",
    "        current_node.calculate_score(config)\n",
    "\n",
    "        new_node = Node(strategy=current_node.strategy, solution=solution, evaluation=evaluation,\n",
    "                        critic_score=critic_score, parent=current_node, question=question, config=config)\n",
    "        current_node.children.append(new_node)\n",
    "\n",
    "    elif current_node.evaluation == \"Refine\":\n",
    "        # Get reflections and refine solution\n",
    "        log = execute_sas_code(current_node.solution)\n",
    "        try:\n",
    "            error_reflection = critic._get_error_reflection(current_node.question, current_node.solution, log)\n",
    "            requirement_reflection = critic._get_requirement_reflection(current_node.question, current_node.solution,\n",
    "                                                                        log)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error during reflections generation : {e}\")\n",
    "            raise\n",
    "\n",
    "        feedback = \"\"\n",
    "        if error_reflection.error_count > 0:\n",
    "            feedback += \"Errors:\\n\"\n",
    "            feedback += f\"- {error_reflection.error_log}\\n\"\n",
    "\n",
    "        if not requirement_reflection.requirements_met:\n",
    "            feedback += \"Missing Requirements:\\n\"\n",
    "            feedback += f\"- {requirement_reflection.missing_requirements}\\n\"\n",
    "\n",
    "        # Generate reflections using Thinker\n",
    "        logging.info(f\"Generating reflections for node: {current_node.strategy}\")\n",
    "        reflections = thinker.generate_reflections(current_node.question, current_node.solution, feedback, log,\n",
    "                                                   current_node.strategy)\n",
    "\n",
    "        if reflections == \"the code is good\":\n",
    "            # If no issues, simply append the current node again (no changes)\n",
    "            logging.info(f\"No issues found, appending current node again: {current_node.strategy}\")\n",
    "            evaluation, critic_score, critic_feedback = critic.evaluate_solution(\n",
    "                current_node.question, current_node.solution, current_node.strategy\n",
    "            )\n",
    "            new_node = Node(strategy=current_node.strategy, solution=current_node.solution, evaluation=evaluation,\n",
    "                            critic_score=critic_score, parent=current_node, question=question, config=config)\n",
    "            current_node.children.append(new_node)\n",
    "        else:\n",
    "            # Refine solution using Debugger\n",
    "            logging.info(f\"Refining solution for node: {current_node.strategy}\")\n",
    "            refined_solution = debugger.generate_refinement(question, current_node.solution, reflections)\n",
    "            logging.info(f\"Evaluating refined solution: {refined_solution}\")\n",
    "            evaluation, critic_score, feedback = critic.evaluate_solution(question, refined_solution,\n",
    "                                                                          current_node.strategy)\n",
    "\n",
    "            # Create new node for refined solution\n",
    "            new_node = Node(strategy=current_node.strategy, solution=refined_solution, evaluation=evaluation,\n",
    "                            critic_score=critic_score, parent=current_node, question=question, config=config)\n",
    "            current_node.children.append(new_node)\n",
    "\n",
    "            # Dynamic expansion based on Critic's score\n",
    "            if critic_score > config[\"expansion_threshold\"] and current_node.depth < max_depth:\n",
    "                logging.info(\n",
    "                    f\"Critic score {critic_score} above expansion threshold {config['expansion_threshold']}. Generating new strategies.\")\n",
    "                new_strategies = thinker.generate_strategies(question)\n",
    "                for new_strategy in new_strategies:\n",
    "                    new_node = Node(strategy=new_strategy, solution=\"\", evaluation=\"Expand\", parent=current_node,\n",
    "                                    question=question, config=config)\n",
    "                    current_node.children.append(new_node)\n",
    "            elif critic_score < config[\"abort_threshold\"]:\n",
    "                logging.info(\n",
    "                    f\"Critic score {critic_score} below abort threshold {config['abort_threshold']}. Marking node as Abort.\")\n",
    "                current_node.evaluation = \"Abort\"\n",
    "\n",
    "    return {**state, \"root\": root}\n",
    "\n",
    "def select_node_to_expand(root: Node) -> Node:\n",
    "    \"\"\"Selects a node to expand based on UCB and evaluation.\"\"\"\n",
    "    node = root\n",
    "    while node.children:\n",
    "        expandable_children = [child for child in node.children if child.evaluation == \"Expand\"]\n",
    "        if expandable_children:\n",
    "            logging.info(\"Selecting node to expand...\")\n",
    "            return max(expandable_children, key=lambda child: child.upper_confidence_bound())\n",
    "\n",
    "        refinable_children = [child for child in node.children if child.evaluation == \"Refine\"]\n",
    "        if refinable_children:\n",
    "            logging.info(\"Selecting node to refine...\")\n",
    "            return max(refinable_children, key=lambda child: child.upper_confidence_bound())\n",
    "\n",
    "        abortable_children = [child for child in node.children if child.evaluation == \"Abort\"]\n",
    "        if abortable_children:\n",
    "            logging.info(\"Found abortable node. Moving to parent.\")\n",
    "            if node == root:\n",
    "                return node\n",
    "            else:\n",
    "                node = node.parent\n",
    "        else:\n",
    "            node = node.children[0]\n",
    "\n",
    "    return node\n",
    "\n",
    "def should_continue(state: TreeState) -> str:\n",
    "    \"\"\"Determines whether the search should continue.\"\"\"\n",
    "    root = state[\"root\"]\n",
    "\n",
    "    # If a solution is found, stop\n",
    "    if any(node.evaluation == \"Accept\" for node in root._get_all_children()):\n",
    "        logging.info(\"Solution found. Stopping...\")\n",
    "        return END\n",
    "\n",
    "    # If any node is marked for expansion, continue\n",
    "    if any(node.evaluation == \"Expand\" for node in root._get_all_children()):\n",
    "        logging.info(\"Expansion required. Continuing...\")\n",
    "        return \"expand\"\n",
    "\n",
    "    # If any node is marked for expansion, continue\n",
    "    if any(node.evaluation == \"Refine\" for node in root._get_all_children()):\n",
    "        logging.info(\"Refinement required. Continuing...\")\n",
    "        return \"expand\"\n",
    "\n",
    "    # If max depth is reached for all nodes, stop\n",
    "    if all(node.depth >= 5 for node in root._get_all_children()):\n",
    "        logging.info(\"Max depth reached. Stopping...\")\n",
    "        return END\n",
    "\n",
    "    logging.info(\"No action determined. Continuing by default...\")\n",
    "    return \"expand\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "945efea4-591f-4647-a6da-b94c536a2150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded as API: https://qwen-qwen2-5-coder-artifacts.hf.space ✔\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-25 12:31:20,994 - INFO - HTTP Request: GET https://qwen-qwen2-5-coder-artifacts.hf.space/config \"HTTP/1.1 200 OK\"\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:22,105 - INFO - HTTP Request: GET https://qwen-qwen2-5-coder-artifacts.hf.space/gradio_api/info?serialize=False \"HTTP/1.1 200 OK\"\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:22,117 - INFO - Returning existing instance of CachedMetadata.\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:22,120 - INFO - Generating initial strategies for question: \n",
      "La liste des véhicules ayant enregistré une forte sinistralité au cours des 5 dernières années (Volet MAT) :\n",
      "\n",
      "-\tLe nbre = 5 sinistres \n",
      "-\tLe coût total : 10000dt\n",
      " \n",
      "Les critères que nous aimerions inclure sont les suivants :\n",
      "                                                                                                                                                                                                                                             \n",
      "•\tMarque et modèle du véhicule\n",
      "•\tNombre total de sinistres déclarés par véhicule\n",
      "•\tMontant total des indemnités versées\n",
      "•\tTypes de sinistres les plus fréquents\n",
      "•\tLa S/P\n",
      "•\tAvec les autres critères habituels du tableau (date déclaration- date sinistre – garantie facultative si existe……)\n",
      "    \n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:22,126 - INFO - Generating strategies for question: \n",
      "La liste des véhicules ayant enregistré une forte sinistralité au cours des 5 dernières années (Volet MAT) :\n",
      "\n",
      "-\tLe nbre = 5 sinistres \n",
      "-\tLe coût total : 10000dt\n",
      " \n",
      "Les critères que nous aimerions inclure sont les suivants :\n",
      "                                                                                                                                                                                                                                             \n",
      "•\tMarque et modèle du véhicule\n",
      "•\tNombre total de sinistres déclarés par véhicule\n",
      "•\tMontant total des indemnités versées\n",
      "•\tTypes de sinistres les plus fréquents\n",
      "•\tLa S/P\n",
      "•\tAvec les autres critères habituels du tableau (date déclaration- date sinistre – garantie facultative si existe……)\n",
      "    \n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:23,365 - INFO - HTTP Request: GET https://qwen-qwen2-5-coder-artifacts.hf.space/gradio_api/heartbeat/f7914f4e-7159-43b5-845b-ef21fa0cc81a \"HTTP/1.1 200 OK\"\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:26,909 - INFO - Generated strategy 1: Aggregate sinistres from `SKANDERH.VUE_SINISTRE_2022` by `NUM_POLICE`, filtering for `TYPE_SINISTRE` = 'MAT' and `SURVENANCE` within the last 5 years, calculate the total number of sinistres and total `REGLEMENTS_TOTALS` for each `NUM_POLICE`, filter for those with at least 5 sinistres and total reglements above 10000, then join with policy data to retrieve vehicle make and model.\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:28,993 - INFO - Generated strategy 2: Aggregate sinistres from `SKANDERH.VUE_SINISTRE_2022` by `NUM_POLICE`, filtering for `TYPE_SINISTRE` = 'MAT' and `SURVENANCE` within the last 5 years. Calculate the total number of sinistres and total `REGLEMENTS_TOTALS` for each `NUM_POLICE`. Filter for those with at least 5 sinistres and total reglements above 10000. Join with the policy dataframe to retrieve vehicle make and model. Calculate the most frequent `TYPE_SINISTRE` for each `NUM_POLICE`. Also, calculate the sinistre to policy ratio by joining with `NUM_POLICE` count from the policy table. Finally, retrieve the 'date declaration' and 'date sinistre' from `SKANDERH.VUE_SINISTRE_2022` and identify if a guarantee is 'facultative' based on column names.\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:31,324 - INFO - Generated strategy 3: Aggregate sinistres from `SKANDERH.VUE_SINISTRE_2022` by `NUM_POLICE`, filtering for `TYPE_SINISTRE` = 'MAT' and `SURVENANCE` within the last 5 years. Calculate the total number of sinistres and total `REGLEMENTS_TOTALS` for each `NUM_POLICE`. Filter for those with at least 5 sinistres and total reglements above 10000. Join with the policy dataframe to retrieve vehicle make and model. Calculate the most frequent `TYPE_SINISTRE` for each `NUM_POLICE`. Also, calculate the sinistre to policy ratio by joining with `NUM_POLICE` count from the policy table. Finally, retrieve the 'date declaration' and 'date sinistre' from `SKANDERH.VUE_SINISTRE_2022` and identify if a guarantee is 'facultative' based on column names. Instead of calculating the most frequent type of sinistre for every vehicle, return a count of the number of 'MAT' sinistre and a count of the number of 'CRP' sinistre.\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:33,539 - INFO - Generated strategy 4: Aggregate sinistres from `SKANDERH.VUE_SINISTRE_2022` by `NUM_POLICE`, filtering for `TYPE_SINISTRE` = 'MAT' and `SURVENANCE` within the last 5 years. Calculate the total number of sinistres (COUNT) and total `REGLEMENTS_TOTALS` for each `NUM_POLICE`. Filter for those with at least 5 sinistres and total reglements above 10000. Join with the policy dataframe to retrieve vehicle make and model. Calculate the number of 'MAT' sinistres and the number of 'CRP' sinistres. Also, calculate the sinistre to policy ratio by joining with `NUM_POLICE` count from the policy table. Finally, retrieve the 'date declaration' and 'date sinistre' from `SKANDERH.VUE_SINISTRE_2022`. Identify if a guarantee is 'facultative' based on column names by checking if a column name contains 'FACULTATIVE'.\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:35,739 - INFO - Generated strategy 5: Aggregate sinistres from `SKANDERH.VUE_SINISTRE_2022` by `NUM_POLICE`, filtering for `TYPE_SINISTRE` = 'MAT' and `SURVENANCE` within the last 5 years. Calculate the total number of sinistres (COUNT) and total `REGLEMENTS_TOTALS` for each `NUM_POLICE`. Filter for those with at least 5 sinistres and total reglements above 10000. Join with the policy dataframe to retrieve vehicle make and model. Calculate the number of 'MAT' sinistres and the number of 'CRP' sinistres. Also, calculate the sinistre to policy ratio by joining with a count of distinct `NUM_POLICE` from the policy table. Finally, retrieve the 'date declaration' and 'date sinistre' from `SKANDERH.VUE_SINISTRE_2022`. Identify if a guarantee is 'facultative' based on column names by checking if a column name contains 'FAC'.\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:35,741 - INFO - Generated strategies: [\"Aggregate sinistres from `SKANDERH.VUE_SINISTRE_2022` by `NUM_POLICE`, filtering for `TYPE_SINISTRE` = 'MAT' and `SURVENANCE` within the last 5 years, calculate the total number of sinistres and total `REGLEMENTS_TOTALS` for each `NUM_POLICE`, filter for those with at least 5 sinistres and total reglements above 10000, then join with policy data to retrieve vehicle make and model.\", \"Aggregate sinistres from `SKANDERH.VUE_SINISTRE_2022` by `NUM_POLICE`, filtering for `TYPE_SINISTRE` = 'MAT' and `SURVENANCE` within the last 5 years. Calculate the total number of sinistres and total `REGLEMENTS_TOTALS` for each `NUM_POLICE`. Filter for those with at least 5 sinistres and total reglements above 10000. Join with the policy dataframe to retrieve vehicle make and model. Calculate the most frequent `TYPE_SINISTRE` for each `NUM_POLICE`. Also, calculate the sinistre to policy ratio by joining with `NUM_POLICE` count from the policy table. Finally, retrieve the 'date declaration' and 'date sinistre' from `SKANDERH.VUE_SINISTRE_2022` and identify if a guarantee is 'facultative' based on column names.\", \"Aggregate sinistres from `SKANDERH.VUE_SINISTRE_2022` by `NUM_POLICE`, filtering for `TYPE_SINISTRE` = 'MAT' and `SURVENANCE` within the last 5 years. Calculate the total number of sinistres and total `REGLEMENTS_TOTALS` for each `NUM_POLICE`. Filter for those with at least 5 sinistres and total reglements above 10000. Join with the policy dataframe to retrieve vehicle make and model. Calculate the most frequent `TYPE_SINISTRE` for each `NUM_POLICE`. Also, calculate the sinistre to policy ratio by joining with `NUM_POLICE` count from the policy table. Finally, retrieve the 'date declaration' and 'date sinistre' from `SKANDERH.VUE_SINISTRE_2022` and identify if a guarantee is 'facultative' based on column names. Instead of calculating the most frequent type of sinistre for every vehicle, return a count of the number of 'MAT' sinistre and a count of the number of 'CRP' sinistre.\", \"Aggregate sinistres from `SKANDERH.VUE_SINISTRE_2022` by `NUM_POLICE`, filtering for `TYPE_SINISTRE` = 'MAT' and `SURVENANCE` within the last 5 years. Calculate the total number of sinistres (COUNT) and total `REGLEMENTS_TOTALS` for each `NUM_POLICE`. Filter for those with at least 5 sinistres and total reglements above 10000. Join with the policy dataframe to retrieve vehicle make and model. Calculate the number of 'MAT' sinistres and the number of 'CRP' sinistres. Also, calculate the sinistre to policy ratio by joining with `NUM_POLICE` count from the policy table. Finally, retrieve the 'date declaration' and 'date sinistre' from `SKANDERH.VUE_SINISTRE_2022`. Identify if a guarantee is 'facultative' based on column names by checking if a column name contains 'FACULTATIVE'.\", \"Aggregate sinistres from `SKANDERH.VUE_SINISTRE_2022` by `NUM_POLICE`, filtering for `TYPE_SINISTRE` = 'MAT' and `SURVENANCE` within the last 5 years. Calculate the total number of sinistres (COUNT) and total `REGLEMENTS_TOTALS` for each `NUM_POLICE`. Filter for those with at least 5 sinistres and total reglements above 10000. Join with the policy dataframe to retrieve vehicle make and model. Calculate the number of 'MAT' sinistres and the number of 'CRP' sinistres. Also, calculate the sinistre to policy ratio by joining with a count of distinct `NUM_POLICE` from the policy table. Finally, retrieve the 'date declaration' and 'date sinistre' from `SKANDERH.VUE_SINISTRE_2022`. Identify if a guarantee is 'facultative' based on column names by checking if a column name contains 'FAC'.\"]\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:35,742 - INFO - Backpropagating reward: 0 for node with strategy: Root\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:35,744 - INFO - Calculating score for node with strategy: Root\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:35,745 - INFO - Node score calculated: 0.0\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:35,748 - INFO - Backpropagating reward: 0 for node with strategy: Aggregate sinistres from `SKANDERH.VUE_SINISTRE_2022` by `NUM_POLICE`, filtering for `TYPE_SINISTRE` = 'MAT' and `SURVENANCE` within the last 5 years, calculate the total number of sinistres and total `REGLEMENTS_TOTALS` for each `NUM_POLICE`, filter for those with at least 5 sinistres and total reglements above 10000, then join with policy data to retrieve vehicle make and model.\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:35,749 - INFO - Calculating score for node with strategy: Aggregate sinistres from `SKANDERH.VUE_SINISTRE_2022` by `NUM_POLICE`, filtering for `TYPE_SINISTRE` = 'MAT' and `SURVENANCE` within the last 5 years, calculate the total number of sinistres and total `REGLEMENTS_TOTALS` for each `NUM_POLICE`, filter for those with at least 5 sinistres and total reglements above 10000, then join with policy data to retrieve vehicle make and model.\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:35,750 - INFO - Node score calculated: 0.0\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:35,750 - INFO - Calculating score for node with strategy: Root\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:35,751 - INFO - Node score calculated: 0.0\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:35,751 - INFO - Backpropagating reward: 0 for node with strategy: Aggregate sinistres from `SKANDERH.VUE_SINISTRE_2022` by `NUM_POLICE`, filtering for `TYPE_SINISTRE` = 'MAT' and `SURVENANCE` within the last 5 years. Calculate the total number of sinistres and total `REGLEMENTS_TOTALS` for each `NUM_POLICE`. Filter for those with at least 5 sinistres and total reglements above 10000. Join with the policy dataframe to retrieve vehicle make and model. Calculate the most frequent `TYPE_SINISTRE` for each `NUM_POLICE`. Also, calculate the sinistre to policy ratio by joining with `NUM_POLICE` count from the policy table. Finally, retrieve the 'date declaration' and 'date sinistre' from `SKANDERH.VUE_SINISTRE_2022` and identify if a guarantee is 'facultative' based on column names.\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:35,752 - INFO - Calculating score for node with strategy: Aggregate sinistres from `SKANDERH.VUE_SINISTRE_2022` by `NUM_POLICE`, filtering for `TYPE_SINISTRE` = 'MAT' and `SURVENANCE` within the last 5 years. Calculate the total number of sinistres and total `REGLEMENTS_TOTALS` for each `NUM_POLICE`. Filter for those with at least 5 sinistres and total reglements above 10000. Join with the policy dataframe to retrieve vehicle make and model. Calculate the most frequent `TYPE_SINISTRE` for each `NUM_POLICE`. Also, calculate the sinistre to policy ratio by joining with `NUM_POLICE` count from the policy table. Finally, retrieve the 'date declaration' and 'date sinistre' from `SKANDERH.VUE_SINISTRE_2022` and identify if a guarantee is 'facultative' based on column names.\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:35,752 - INFO - Node score calculated: 0.0\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:35,753 - INFO - Calculating score for node with strategy: Root\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:35,753 - INFO - Node score calculated: 0.0\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:35,754 - INFO - Backpropagating reward: 0 for node with strategy: Aggregate sinistres from `SKANDERH.VUE_SINISTRE_2022` by `NUM_POLICE`, filtering for `TYPE_SINISTRE` = 'MAT' and `SURVENANCE` within the last 5 years. Calculate the total number of sinistres and total `REGLEMENTS_TOTALS` for each `NUM_POLICE`. Filter for those with at least 5 sinistres and total reglements above 10000. Join with the policy dataframe to retrieve vehicle make and model. Calculate the most frequent `TYPE_SINISTRE` for each `NUM_POLICE`. Also, calculate the sinistre to policy ratio by joining with `NUM_POLICE` count from the policy table. Finally, retrieve the 'date declaration' and 'date sinistre' from `SKANDERH.VUE_SINISTRE_2022` and identify if a guarantee is 'facultative' based on column names. Instead of calculating the most frequent type of sinistre for every vehicle, return a count of the number of 'MAT' sinistre and a count of the number of 'CRP' sinistre.\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:35,754 - INFO - Calculating score for node with strategy: Aggregate sinistres from `SKANDERH.VUE_SINISTRE_2022` by `NUM_POLICE`, filtering for `TYPE_SINISTRE` = 'MAT' and `SURVENANCE` within the last 5 years. Calculate the total number of sinistres and total `REGLEMENTS_TOTALS` for each `NUM_POLICE`. Filter for those with at least 5 sinistres and total reglements above 10000. Join with the policy dataframe to retrieve vehicle make and model. Calculate the most frequent `TYPE_SINISTRE` for each `NUM_POLICE`. Also, calculate the sinistre to policy ratio by joining with `NUM_POLICE` count from the policy table. Finally, retrieve the 'date declaration' and 'date sinistre' from `SKANDERH.VUE_SINISTRE_2022` and identify if a guarantee is 'facultative' based on column names. Instead of calculating the most frequent type of sinistre for every vehicle, return a count of the number of 'MAT' sinistre and a count of the number of 'CRP' sinistre.\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:35,755 - INFO - Node score calculated: 0.0\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:35,756 - INFO - Calculating score for node with strategy: Root\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:35,756 - INFO - Node score calculated: 0.0\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:35,757 - INFO - Backpropagating reward: 0 for node with strategy: Aggregate sinistres from `SKANDERH.VUE_SINISTRE_2022` by `NUM_POLICE`, filtering for `TYPE_SINISTRE` = 'MAT' and `SURVENANCE` within the last 5 years. Calculate the total number of sinistres (COUNT) and total `REGLEMENTS_TOTALS` for each `NUM_POLICE`. Filter for those with at least 5 sinistres and total reglements above 10000. Join with the policy dataframe to retrieve vehicle make and model. Calculate the number of 'MAT' sinistres and the number of 'CRP' sinistres. Also, calculate the sinistre to policy ratio by joining with `NUM_POLICE` count from the policy table. Finally, retrieve the 'date declaration' and 'date sinistre' from `SKANDERH.VUE_SINISTRE_2022`. Identify if a guarantee is 'facultative' based on column names by checking if a column name contains 'FACULTATIVE'.\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:35,757 - INFO - Calculating score for node with strategy: Aggregate sinistres from `SKANDERH.VUE_SINISTRE_2022` by `NUM_POLICE`, filtering for `TYPE_SINISTRE` = 'MAT' and `SURVENANCE` within the last 5 years. Calculate the total number of sinistres (COUNT) and total `REGLEMENTS_TOTALS` for each `NUM_POLICE`. Filter for those with at least 5 sinistres and total reglements above 10000. Join with the policy dataframe to retrieve vehicle make and model. Calculate the number of 'MAT' sinistres and the number of 'CRP' sinistres. Also, calculate the sinistre to policy ratio by joining with `NUM_POLICE` count from the policy table. Finally, retrieve the 'date declaration' and 'date sinistre' from `SKANDERH.VUE_SINISTRE_2022`. Identify if a guarantee is 'facultative' based on column names by checking if a column name contains 'FACULTATIVE'.\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:35,758 - INFO - Node score calculated: 0.0\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:35,758 - INFO - Calculating score for node with strategy: Root\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:35,759 - INFO - Node score calculated: 0.0\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:35,759 - INFO - Backpropagating reward: 0 for node with strategy: Aggregate sinistres from `SKANDERH.VUE_SINISTRE_2022` by `NUM_POLICE`, filtering for `TYPE_SINISTRE` = 'MAT' and `SURVENANCE` within the last 5 years. Calculate the total number of sinistres (COUNT) and total `REGLEMENTS_TOTALS` for each `NUM_POLICE`. Filter for those with at least 5 sinistres and total reglements above 10000. Join with the policy dataframe to retrieve vehicle make and model. Calculate the number of 'MAT' sinistres and the number of 'CRP' sinistres. Also, calculate the sinistre to policy ratio by joining with a count of distinct `NUM_POLICE` from the policy table. Finally, retrieve the 'date declaration' and 'date sinistre' from `SKANDERH.VUE_SINISTRE_2022`. Identify if a guarantee is 'facultative' based on column names by checking if a column name contains 'FAC'.\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:35,760 - INFO - Calculating score for node with strategy: Aggregate sinistres from `SKANDERH.VUE_SINISTRE_2022` by `NUM_POLICE`, filtering for `TYPE_SINISTRE` = 'MAT' and `SURVENANCE` within the last 5 years. Calculate the total number of sinistres (COUNT) and total `REGLEMENTS_TOTALS` for each `NUM_POLICE`. Filter for those with at least 5 sinistres and total reglements above 10000. Join with the policy dataframe to retrieve vehicle make and model. Calculate the number of 'MAT' sinistres and the number of 'CRP' sinistres. Also, calculate the sinistre to policy ratio by joining with a count of distinct `NUM_POLICE` from the policy table. Finally, retrieve the 'date declaration' and 'date sinistre' from `SKANDERH.VUE_SINISTRE_2022`. Identify if a guarantee is 'facultative' based on column names by checking if a column name contains 'FAC'.\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:35,761 - INFO - Node score calculated: 0.0\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:35,761 - INFO - Calculating score for node with strategy: Root\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:35,762 - INFO - Node score calculated: 0.0\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:35,762 - INFO - Expansion required. Continuing...\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:35,763 - INFO - Expanding tree for question: \n",
      "La liste des véhicules ayant enregistré une forte sinistralité au cours des 5 dernières années (Volet MAT) :\n",
      "\n",
      "-\tLe nbre = 5 sinistres \n",
      "-\tLe coût total : 10000dt\n",
      " \n",
      "Les critères que nous aimerions inclure sont les suivants :\n",
      "                                                                                                                                                                                                                                             \n",
      "•\tMarque et modèle du véhicule\n",
      "•\tNombre total de sinistres déclarés par véhicule\n",
      "•\tMontant total des indemnités versées\n",
      "•\tTypes de sinistres les plus fréquents\n",
      "•\tLa S/P\n",
      "•\tAvec les autres critères habituels du tableau (date déclaration- date sinistre – garantie facultative si existe……)\n",
      "    \n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:35,763 - INFO - Selecting node to expand...\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:35,764 - INFO - Selected node for expansion: Aggregate sinistres from `SKANDERH.VUE_SINISTRE_2022` by `NUM_POLICE`, filtering for `TYPE_SINISTRE` = 'MAT' and `SURVENANCE` within the last 5 years, calculate the total number of sinistres and total `REGLEMENTS_TOTALS` for each `NUM_POLICE`, filter for those with at least 5 sinistres and total reglements above 10000, then join with policy data to retrieve vehicle make and model.\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:35,764 - INFO - Generating solution for node: Aggregate sinistres from `SKANDERH.VUE_SINISTRE_2022` by `NUM_POLICE`, filtering for `TYPE_SINISTRE` = 'MAT' and `SURVENANCE` within the last 5 years, calculate the total number of sinistres and total `REGLEMENTS_TOTALS` for each `NUM_POLICE`, filter for those with at least 5 sinistres and total reglements above 10000, then join with policy data to retrieve vehicle make and model.\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:35,765 - INFO - Generating solution for question: \n",
      "La liste des véhicules ayant enregistré une forte sinistralité au cours des 5 dernières années (Volet MAT) :\n",
      "\n",
      "-\tLe nbre = 5 sinistres \n",
      "-\tLe coût total : 10000dt\n",
      " \n",
      "Les critères que nous aimerions inclure sont les suivants :\n",
      "                                                                                                                                                                                                                                             \n",
      "•\tMarque et modèle du véhicule\n",
      "•\tNombre total de sinistres déclarés par véhicule\n",
      "•\tMontant total des indemnités versées\n",
      "•\tTypes de sinistres les plus fréquents\n",
      "•\tLa S/P\n",
      "•\tAvec les autres critères habituels du tableau (date déclaration- date sinistre – garantie facultative si existe……)\n",
      "     with strategy: Aggregate sinistres from `SKANDERH.VUE_SINISTRE_2022` by `NUM_POLICE`, filtering for `TYPE_SINISTRE` = 'MAT' and `SURVENANCE` within the last 5 years, calculate the total number of sinistres and total `REGLEMENTS_TOTALS` for each `NUM_POLICE`, filter for those with at least 5 sinistres and total reglements above 10000, then join with policy data to retrieve vehicle make and model.\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:39,250 - INFO - Generated solution:\n",
      "```sas\n",
      "PROC SQL;\n",
      "    CREATE TABLE work.sinistres_mat_2022 AS\n",
      "    SELECT\n",
      "        NUM_POLICE,\n",
      "        NUMERO_SINISTRE,\n",
      "        TYPE_SINISTRE,\n",
      "        SURVENANCE,\n",
      "        (sum(REGLEMENT_INVENTAIRE + REGLEMENT_EXTRA_2 + REGLEMENT_EXTRA)) as REGLEMENTS_TOTALS\n",
      "    FROM SKANDERH.VUE_SINISTRE_2022\n",
      "    WHERE TYPE_SINISTRE = 'MAT' AND SURVENANCE >= YEAR(TODAY()) - 5\n",
      "    GROUP BY NUM_POLICE, NUMERO_SINISTRE, TYPE_SINISTRE, SURVENANCE\n",
      "    ;\n",
      "QUIT;\n",
      "\n",
      "PROC SQL;\n",
      "    CREATE TABLE work.agg_sinistres_mat AS\n",
      "    SELECT\n",
      "        NUM_POLICE,\n",
      "        COUNT(NUMERO_SINISTRE) AS NBR_SINISTRES,\n",
      "        SUM(REGLEMENTS_TOTALS) AS TOTAL_REGLEMENTS\n",
      "    FROM work.sinistres_mat_2022\n",
      "    GROUP BY NUM_POLICE\n",
      "    HAVING COUNT(NUMERO_SINISTRE) >= 5 AND SUM(REGLEMENTS_TOTALS) > 10000\n",
      "    ;\n",
      "QUIT;\n",
      "\n",
      "PROC SQL;\n",
      "    CREATE TABLE work.final_result AS\n",
      "    SELECT\n",
      "        a.NUM_POLICE,\n",
      "        b.NBR_SINISTRES,\n",
      "        b.TOTAL_REGLEMENTS\n",
      "    FROM work.agg_sinistres_mat as b\n",
      "    LEFT JOIN\n",
      "         RADHOUAN.POLICE_2022 as a\n",
      "    ON a.CNUMPOLIZZA = b.NUM_POLICE\n",
      "    ;\n",
      "QUIT;\n",
      "\n",
      "PROC PRINT DATA=work.final_result;\n",
      "RUN;\n",
      "```\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:39,251 - INFO - Evaluating solution: ```sas\n",
      "PROC SQL;\n",
      "    CREATE TABLE work.sinistres_mat_2022 AS\n",
      "    SELECT\n",
      "        NUM_POLICE,\n",
      "        NUMERO_SINISTRE,\n",
      "        TYPE_SINISTRE,\n",
      "        SURVENANCE,\n",
      "        (sum(REGLEMENT_INVENTAIRE + REGLEMENT_EXTRA_2 + REGLEMENT_EXTRA)) as REGLEMENTS_TOTALS\n",
      "    FROM SKANDERH.VUE_SINISTRE_2022\n",
      "    WHERE TYPE_SINISTRE = 'MAT' AND SURVENANCE >= YEAR(TODAY()) - 5\n",
      "    GROUP BY NUM_POLICE, NUMERO_SINISTRE, TYPE_SINISTRE, SURVENANCE\n",
      "    ;\n",
      "QUIT;\n",
      "\n",
      "PROC SQL;\n",
      "    CREATE TABLE work.agg_sinistres_mat AS\n",
      "    SELECT\n",
      "        NUM_POLICE,\n",
      "        COUNT(NUMERO_SINISTRE) AS NBR_SINISTRES,\n",
      "        SUM(REGLEMENTS_TOTALS) AS TOTAL_REGLEMENTS\n",
      "    FROM work.sinistres_mat_2022\n",
      "    GROUP BY NUM_POLICE\n",
      "    HAVING COUNT(NUMERO_SINISTRE) >= 5 AND SUM(REGLEMENTS_TOTALS) > 10000\n",
      "    ;\n",
      "QUIT;\n",
      "\n",
      "PROC SQL;\n",
      "    CREATE TABLE work.final_result AS\n",
      "    SELECT\n",
      "        a.NUM_POLICE,\n",
      "        b.NBR_SINISTRES,\n",
      "        b.TOTAL_REGLEMENTS\n",
      "    FROM work.agg_sinistres_mat as b\n",
      "    LEFT JOIN\n",
      "         RADHOUAN.POLICE_2022 as a\n",
      "    ON a.CNUMPOLIZZA = b.NUM_POLICE\n",
      "    ;\n",
      "QUIT;\n",
      "\n",
      "PROC PRINT DATA=work.final_result;\n",
      "RUN;\n",
      "```\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:39,251 - INFO - Evaluating solution for question: \n",
      "La liste des véhicules ayant enregistré une forte sinistralité au cours des 5 dernières années (Volet MAT) :\n",
      "\n",
      "-\tLe nbre = 5 sinistres \n",
      "-\tLe coût total : 10000dt\n",
      " \n",
      "Les critères que nous aimerions inclure sont les suivants :\n",
      "                                                                                                                                                                                                                                             \n",
      "•\tMarque et modèle du véhicule\n",
      "•\tNombre total de sinistres déclarés par véhicule\n",
      "•\tMontant total des indemnités versées\n",
      "•\tTypes de sinistres les plus fréquents\n",
      "•\tLa S/P\n",
      "•\tAvec les autres critères habituels du tableau (date déclaration- date sinistre – garantie facultative si existe……)\n",
      "    \n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:39,253 - INFO - Executing SAS code...\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:39,861 - INFO - SAS code executed. Returning log.\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:39,863 - INFO - Getting error reflection...\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:41,388 - INFO - Error reflection: Error Count: 2, Error Log: ERROR: File RADHOUAN.POLICE_2022.DATA does not exist.\n",
      "NOTE: PROC SQL set option NOEXEC and will continue to check the syntax of statements.\n",
      "NOTE: The SAS System stopped processing this step because of errors.\n",
      "ERROR: File WORK.FINAL_RESULT.DATA does not exist.\n",
      "NOTE: The SAS System stopped processing this step because of errors., Error Category: runtime\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:41,390 - INFO - Getting requirement reflection...\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:44,310 - INFO - Requirement reflection: Missing Requirements: The code is missing several requirements:\n",
      "\n",
      "1.  **Vehicle Make and Model:** The code does not include any information about the vehicle's make and model. This information is not present in the provided metadata, so it's impossible to add it with the provided table.\n",
      "2.  **Most Frequent Types of Claims:** The code does not identify the most frequent types of claims for each vehicle. The query asks for 'Types de sinistres les plus fréquents', but the code only filters for 'MAT' type claims.\n",
      "3.  **S/P (Sinistre/Prime Ratio):** The code does not calculate the S/P ratio. This would need premium data which is not part of the provided metadata.\n",
      "4.  **Additional Table Columns:** The code does not include the 'date declaration', 'date sinistre', or 'garantie facultative' columns. These are not present in the provided metadata table, so they can't be added.\n",
      "5.  **Data Source:** The code uses `SKANDERH.VUE_SINISTRE_2022` which does not contain the vehicle's information. The query is about vehicles, and the provided table is about claims. A table with vehicle information should be included.\n",
      "6. **Join with police table**: the join with the police table is done with a field name that seems wrong CNUMPOLIZZA instead of NUM_POLICE, Requirements Met: False\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:44,311 - INFO - Getting strategy adherence reflection...\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:48,877 - INFO - Strategy adherence reflection: Adherence Score: 0.6, Reasoning: The SAS code partially adheres to the strategy, but there are some significant deviations.\n",
      "\n",
      "**Adherence:**\n",
      "\n",
      "*   **Filtering by `TYPE_SINISTRE`:** The code correctly filters for `TYPE_SINISTRE` = 'MAT'.\n",
      "*   **Filtering by `SURVENANCE`:** The code correctly filters for `SURVENANCE` within the last 5 years.\n",
      "*   **Grouping by `NUM_POLICE`:** The code groups by `NUM_POLICE` to calculate aggregates.\n",
      "*   **Filtering by number of sinistres and total cost:** The code filters for `NBR_SINISTRES` >= 5 and `TOTAL_REGLEMENTS` > 10000.\n",
      "\n",
      "**Deviations:**\n",
      "\n",
      "*   **Incorrect aggregation of `REGLEMENTS_TOTALS`:** The code calculates `REGLEMENTS_TOTALS` as `sum(REGLEMENT_INVENTAIRE + REGLEMENT_EXTRA_2 + REGLEMENT_EXTRA)`. This is not aligned with the database description which states that the database provides \"descriptions détaillées des réserves, charges et règlements par garanties\". The code should use the pre-calculated sum of all reglements available in the table (if available), or explicitly select all reglement columns per guarantee.\n",
      "*   **Unnecessary grouping in the first query:** The first query groups by `NUM_POLICE`, `NUMERO_SINISTRE`, `TYPE_SINISTRE`, and `SURVENANCE`. This is unnecessary and incorrect. It should group only by `NUM_POLICE` to calculate total reglements and sinistres per police.\n",
      "*   **Joining with policy data:** The strategy mentions joining with policy data to retrieve vehicle make and model but the provided code does not include vehicle make and model, also the join is done using `CNUMPOLIZZA` which is not present in the metadata, it should be `NUM_POLICE`.\n",
      "*   **Missing details:** The strategy mentions including details such as date of declaration, date of sinistre and facultative guarantee. These details are not included in the generated code.\n",
      "\n",
      "**Score:**\n",
      "\n",
      "Given these deviations, especially the incorrect calculation of `REGLEMENTS_TOTALS`, unnecessary grouping in the first query, and the missing join with policy data, the adherence score is set to 0.6. While the core filtering and aggregation logic is present, the incorrect implementation of key aspects makes the code not fully aligned with the strategy.\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:48,879 - INFO - Evaluation: Refine, Critic Score: 0.55, Feedback: Errors:\n",
      "- ERROR: File RADHOUAN.POLICE_2022.DATA does not exist.\n",
      "NOTE: PROC SQL set option NOEXEC and will continue to check the syntax of statements.\n",
      "NOTE: The SAS System stopped processing this step because of errors.\n",
      "ERROR: File WORK.FINAL_RESULT.DATA does not exist.\n",
      "NOTE: The SAS System stopped processing this step because of errors.\n",
      "Missing Requirements:\n",
      "- The code is missing several requirements:\n",
      "\n",
      "1.  **Vehicle Make and Model:** The code does not include any information about the vehicle's make and model. This information is not present in the provided metadata, so it's impossible to add it with the provided table.\n",
      "2.  **Most Frequent Types of Claims:** The code does not identify the most frequent types of claims for each vehicle. The query asks for 'Types de sinistres les plus fréquents', but the code only filters for 'MAT' type claims.\n",
      "3.  **S/P (Sinistre/Prime Ratio):** The code does not calculate the S/P ratio. This would need premium data which is not part of the provided metadata.\n",
      "4.  **Additional Table Columns:** The code does not include the 'date declaration', 'date sinistre', or 'garantie facultative' columns. These are not present in the provided metadata table, so they can't be added.\n",
      "5.  **Data Source:** The code uses `SKANDERH.VUE_SINISTRE_2022` which does not contain the vehicle's information. The query is about vehicles, and the provided table is about claims. A table with vehicle information should be included.\n",
      "6. **Join with police table**: the join with the police table is done with a field name that seems wrong CNUMPOLIZZA instead of NUM_POLICE\n",
      "Strategy Adherence: 0.60 - The SAS code partially adheres to the strategy, but there are some significant deviations.\n",
      "\n",
      "**Adherence:**\n",
      "\n",
      "*   **Filtering by `TYPE_SINISTRE`:** The code correctly filters for `TYPE_SINISTRE` = 'MAT'.\n",
      "*   **Filtering by `SURVENANCE`:** The code correctly filters for `SURVENANCE` within the last 5 years.\n",
      "*   **Grouping by `NUM_POLICE`:** The code groups by `NUM_POLICE` to calculate aggregates.\n",
      "*   **Filtering by number of sinistres and total cost:** The code filters for `NBR_SINISTRES` >= 5 and `TOTAL_REGLEMENTS` > 10000.\n",
      "\n",
      "**Deviations:**\n",
      "\n",
      "*   **Incorrect aggregation of `REGLEMENTS_TOTALS`:** The code calculates `REGLEMENTS_TOTALS` as `sum(REGLEMENT_INVENTAIRE + REGLEMENT_EXTRA_2 + REGLEMENT_EXTRA)`. This is not aligned with the database description which states that the database provides \"descriptions détaillées des réserves, charges et règlements par garanties\". The code should use the pre-calculated sum of all reglements available in the table (if available), or explicitly select all reglement columns per guarantee.\n",
      "*   **Unnecessary grouping in the first query:** The first query groups by `NUM_POLICE`, `NUMERO_SINISTRE`, `TYPE_SINISTRE`, and `SURVENANCE`. This is unnecessary and incorrect. It should group only by `NUM_POLICE` to calculate total reglements and sinistres per police.\n",
      "*   **Joining with policy data:** The strategy mentions joining with policy data to retrieve vehicle make and model but the provided code does not include vehicle make and model, also the join is done using `CNUMPOLIZZA` which is not present in the metadata, it should be `NUM_POLICE`.\n",
      "*   **Missing details:** The strategy mentions including details such as date of declaration, date of sinistre and facultative guarantee. These details are not included in the generated code.\n",
      "\n",
      "**Score:**\n",
      "\n",
      "Given these deviations, especially the incorrect calculation of `REGLEMENTS_TOTALS`, unnecessary grouping in the first query, and the missing join with policy data, the adherence score is set to 0.6. While the core filtering and aggregation logic is present, the incorrect implementation of key aspects makes the code not fully aligned with the strategy.\n",
      "\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:48,879 - INFO - Calculating score for node with strategy: Aggregate sinistres from `SKANDERH.VUE_SINISTRE_2022` by `NUM_POLICE`, filtering for `TYPE_SINISTRE` = 'MAT' and `SURVENANCE` within the last 5 years, calculate the total number of sinistres and total `REGLEMENTS_TOTALS` for each `NUM_POLICE`, filter for those with at least 5 sinistres and total reglements above 10000, then join with policy data to retrieve vehicle make and model.\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:48,880 - INFO - Executing SAS code...\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:49,083 - INFO - SAS code executed. Returning log.\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:49,085 - INFO - Node score calculated: 0.22000000000000003\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:49,087 - INFO - Backpropagating reward: 0 for node with strategy: Aggregate sinistres from `SKANDERH.VUE_SINISTRE_2022` by `NUM_POLICE`, filtering for `TYPE_SINISTRE` = 'MAT' and `SURVENANCE` within the last 5 years, calculate the total number of sinistres and total `REGLEMENTS_TOTALS` for each `NUM_POLICE`, filter for those with at least 5 sinistres and total reglements above 10000, then join with policy data to retrieve vehicle make and model.\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:49,088 - INFO - Calculating score for node with strategy: Aggregate sinistres from `SKANDERH.VUE_SINISTRE_2022` by `NUM_POLICE`, filtering for `TYPE_SINISTRE` = 'MAT' and `SURVENANCE` within the last 5 years, calculate the total number of sinistres and total `REGLEMENTS_TOTALS` for each `NUM_POLICE`, filter for those with at least 5 sinistres and total reglements above 10000, then join with policy data to retrieve vehicle make and model.\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:49,090 - INFO - Executing SAS code...\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:49,296 - INFO - SAS code executed. Returning log.\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:49,297 - INFO - Node score calculated: 0.22000000000000003\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:49,298 - INFO - Calculating score for node with strategy: Aggregate sinistres from `SKANDERH.VUE_SINISTRE_2022` by `NUM_POLICE`, filtering for `TYPE_SINISTRE` = 'MAT' and `SURVENANCE` within the last 5 years, calculate the total number of sinistres and total `REGLEMENTS_TOTALS` for each `NUM_POLICE`, filter for those with at least 5 sinistres and total reglements above 10000, then join with policy data to retrieve vehicle make and model.\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:49,299 - INFO - Executing SAS code...\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:49,503 - INFO - SAS code executed. Returning log.\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:49,504 - INFO - Node score calculated: 0.22000000000000003\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:49,505 - INFO - Calculating score for node with strategy: Root\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:49,506 - INFO - Node score calculated: 0.0\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:49,507 - INFO - Expansion required. Continuing...\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:49,508 - INFO - Expanding tree for question: \n",
      "La liste des véhicules ayant enregistré une forte sinistralité au cours des 5 dernières années (Volet MAT) :\n",
      "\n",
      "-\tLe nbre = 5 sinistres \n",
      "-\tLe coût total : 10000dt\n",
      " \n",
      "Les critères que nous aimerions inclure sont les suivants :\n",
      "                                                                                                                                                                                                                                             \n",
      "•\tMarque et modèle du véhicule\n",
      "•\tNombre total de sinistres déclarés par véhicule\n",
      "•\tMontant total des indemnités versées\n",
      "•\tTypes de sinistres les plus fréquents\n",
      "•\tLa S/P\n",
      "•\tAvec les autres critères habituels du tableau (date déclaration- date sinistre – garantie facultative si existe……)\n",
      "    \n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:49,509 - INFO - Selecting node to expand...\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:49,510 - INFO - Selected node for expansion: Aggregate sinistres from `SKANDERH.VUE_SINISTRE_2022` by `NUM_POLICE`, filtering for `TYPE_SINISTRE` = 'MAT' and `SURVENANCE` within the last 5 years. Calculate the total number of sinistres and total `REGLEMENTS_TOTALS` for each `NUM_POLICE`. Filter for those with at least 5 sinistres and total reglements above 10000. Join with the policy dataframe to retrieve vehicle make and model. Calculate the most frequent `TYPE_SINISTRE` for each `NUM_POLICE`. Also, calculate the sinistre to policy ratio by joining with `NUM_POLICE` count from the policy table. Finally, retrieve the 'date declaration' and 'date sinistre' from `SKANDERH.VUE_SINISTRE_2022` and identify if a guarantee is 'facultative' based on column names.\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:49,511 - INFO - Generating solution for node: Aggregate sinistres from `SKANDERH.VUE_SINISTRE_2022` by `NUM_POLICE`, filtering for `TYPE_SINISTRE` = 'MAT' and `SURVENANCE` within the last 5 years. Calculate the total number of sinistres and total `REGLEMENTS_TOTALS` for each `NUM_POLICE`. Filter for those with at least 5 sinistres and total reglements above 10000. Join with the policy dataframe to retrieve vehicle make and model. Calculate the most frequent `TYPE_SINISTRE` for each `NUM_POLICE`. Also, calculate the sinistre to policy ratio by joining with `NUM_POLICE` count from the policy table. Finally, retrieve the 'date declaration' and 'date sinistre' from `SKANDERH.VUE_SINISTRE_2022` and identify if a guarantee is 'facultative' based on column names.\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:49,512 - INFO - Generating solution for question: \n",
      "La liste des véhicules ayant enregistré une forte sinistralité au cours des 5 dernières années (Volet MAT) :\n",
      "\n",
      "-\tLe nbre = 5 sinistres \n",
      "-\tLe coût total : 10000dt\n",
      " \n",
      "Les critères que nous aimerions inclure sont les suivants :\n",
      "                                                                                                                                                                                                                                             \n",
      "•\tMarque et modèle du véhicule\n",
      "•\tNombre total de sinistres déclarés par véhicule\n",
      "•\tMontant total des indemnités versées\n",
      "•\tTypes de sinistres les plus fréquents\n",
      "•\tLa S/P\n",
      "•\tAvec les autres critères habituels du tableau (date déclaration- date sinistre – garantie facultative si existe……)\n",
      "     with strategy: Aggregate sinistres from `SKANDERH.VUE_SINISTRE_2022` by `NUM_POLICE`, filtering for `TYPE_SINISTRE` = 'MAT' and `SURVENANCE` within the last 5 years. Calculate the total number of sinistres and total `REGLEMENTS_TOTALS` for each `NUM_POLICE`. Filter for those with at least 5 sinistres and total reglements above 10000. Join with the policy dataframe to retrieve vehicle make and model. Calculate the most frequent `TYPE_SINISTRE` for each `NUM_POLICE`. Also, calculate the sinistre to policy ratio by joining with `NUM_POLICE` count from the policy table. Finally, retrieve the 'date declaration' and 'date sinistre' from `SKANDERH.VUE_SINISTRE_2022` and identify if a guarantee is 'facultative' based on column names.\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:56,465 - INFO - Generated solution:\n",
      "```sas\n",
      "proc sql;\n",
      "    create table vs22 as\n",
      "    select \n",
      "        NUMERO_SINISTRE,\n",
      "        NUM_POLICE,\n",
      "        TYPE_SINISTRE,\n",
      "        SURVENANCE,\n",
      "        (case when coalesce(REGLEMENT_INVENTAIRE,0) + coalesce(REGLEMENT_EXTRA_2,0) + coalesce(REGLEMENT_EXTRA,0) is null then 0 else coalesce(REGLEMENT_INVENTAIRE,0) + coalesce(REGLEMENT_EXTRA_2,0) + coalesce(REGLEMENT_EXTRA,0) end) as REGLEMENTS_TOTALS,\n",
      "        '2022' as ANNEE_REFERENCE,\n",
      "        input(substr(NUMERO_SINISTRE, 1, 8), yymmdd10.) as DATE_DECLARATION,\n",
      "        input(substr(NUMERO_SINISTRE, 9, 8), yymmdd10.) as DATE_SINISTRE\n",
      "    from SKANDERH.VUE_SINISTRE_2022\n",
      "    where TYPE_SINISTRE = 'MAT' and SURVENANCE >= year(today()) - 5;\n",
      "    \n",
      "    create table agg_sinistres as\n",
      "    select \n",
      "        NUM_POLICE,\n",
      "        count(*) as nbr_sinistres,\n",
      "        sum(REGLEMENTS_TOTALS) as total_reglements\n",
      "    from vs22\n",
      "    group by NUM_POLICE\n",
      "    having count(*) >= 5 and sum(REGLEMENTS_TOTALS) > 10000;\n",
      "\n",
      "    create table freq_type_sinistre as\n",
      "    select\n",
      "        NUM_POLICE,\n",
      "        TYPE_SINISTRE,\n",
      "        count(*) as count_type,\n",
      "        calculated count_type / sum(count_type) as freq_type\n",
      "    from vs22\n",
      "    group by NUM_POLICE, TYPE_SINISTRE\n",
      "    qualify row_number() over (partition by NUM_POLICE order by count_type desc) = 1;\n",
      "    \n",
      "    create table pol_count as\n",
      "    select\n",
      "        NUM_POLICE,\n",
      "        count(*) as nbr_police\n",
      "    from  RADHOUAN.POLICE\n",
      "    group by NUM_POLICE;\n",
      "    \n",
      "    create table joined_data as\n",
      "    select \n",
      "        a.NUM_POLICE,\n",
      "        b.MARQUE_VEHICULE,\n",
      "        b.MODELE_VEHICULE,\n",
      "        a.nbr_sinistres,\n",
      "        a.total_reglements,\n",
      "        c.TYPE_SINISTRE as most_frequent_type,\n",
      "        a.nbr_sinistres / d.nbr_police as sinistre_policy_ratio,\n",
      "        e.DATE_DECLARATION,\n",
      "        e.DATE_SINISTRE,\n",
      "        case when sum(case when prxname(1) like '%facultative%' then 1 else 0 end) > 0 then 'Yes' else 'No' end as garantie_facultative\n",
      "    from agg_sinistres as a\n",
      "    inner join RADHOUAN.POLICE as b\n",
      "    on a.NUM_POLICE = b.CNUMPOLIZZA\n",
      "    inner join freq_type_sinistre as c\n",
      "    on a.NUM_POLICE = c.NUM_POLICE\n",
      "    inner join pol_count as d\n",
      "    on a.NUM_POLICE = d.NUM_POLICE\n",
      "    inner join vs22 as e\n",
      "    on a.NUM_POLICE = e.NUM_POLICE\n",
      "    group by a.NUM_POLICE,b.MARQUE_VEHICULE,b.MODELE_VEHICULE,a.nbr_sinistres,a.total_reglements,c.TYPE_SINISTRE,a.nbr_sinistres / d.nbr_police,e.DATE_DECLARATION,e.DATE_SINISTRE;\n",
      "    \n",
      "    \n",
      "    select * from joined_data;\n",
      "quit;\n",
      "```\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:56,466 - INFO - Evaluating solution: ```sas\n",
      "proc sql;\n",
      "    create table vs22 as\n",
      "    select \n",
      "        NUMERO_SINISTRE,\n",
      "        NUM_POLICE,\n",
      "        TYPE_SINISTRE,\n",
      "        SURVENANCE,\n",
      "        (case when coalesce(REGLEMENT_INVENTAIRE,0) + coalesce(REGLEMENT_EXTRA_2,0) + coalesce(REGLEMENT_EXTRA,0) is null then 0 else coalesce(REGLEMENT_INVENTAIRE,0) + coalesce(REGLEMENT_EXTRA_2,0) + coalesce(REGLEMENT_EXTRA,0) end) as REGLEMENTS_TOTALS,\n",
      "        '2022' as ANNEE_REFERENCE,\n",
      "        input(substr(NUMERO_SINISTRE, 1, 8), yymmdd10.) as DATE_DECLARATION,\n",
      "        input(substr(NUMERO_SINISTRE, 9, 8), yymmdd10.) as DATE_SINISTRE\n",
      "    from SKANDERH.VUE_SINISTRE_2022\n",
      "    where TYPE_SINISTRE = 'MAT' and SURVENANCE >= year(today()) - 5;\n",
      "    \n",
      "    create table agg_sinistres as\n",
      "    select \n",
      "        NUM_POLICE,\n",
      "        count(*) as nbr_sinistres,\n",
      "        sum(REGLEMENTS_TOTALS) as total_reglements\n",
      "    from vs22\n",
      "    group by NUM_POLICE\n",
      "    having count(*) >= 5 and sum(REGLEMENTS_TOTALS) > 10000;\n",
      "\n",
      "    create table freq_type_sinistre as\n",
      "    select\n",
      "        NUM_POLICE,\n",
      "        TYPE_SINISTRE,\n",
      "        count(*) as count_type,\n",
      "        calculated count_type / sum(count_type) as freq_type\n",
      "    from vs22\n",
      "    group by NUM_POLICE, TYPE_SINISTRE\n",
      "    qualify row_number() over (partition by NUM_POLICE order by count_type desc) = 1;\n",
      "    \n",
      "    create table pol_count as\n",
      "    select\n",
      "        NUM_POLICE,\n",
      "        count(*) as nbr_police\n",
      "    from  RADHOUAN.POLICE\n",
      "    group by NUM_POLICE;\n",
      "    \n",
      "    create table joined_data as\n",
      "    select \n",
      "        a.NUM_POLICE,\n",
      "        b.MARQUE_VEHICULE,\n",
      "        b.MODELE_VEHICULE,\n",
      "        a.nbr_sinistres,\n",
      "        a.total_reglements,\n",
      "        c.TYPE_SINISTRE as most_frequent_type,\n",
      "        a.nbr_sinistres / d.nbr_police as sinistre_policy_ratio,\n",
      "        e.DATE_DECLARATION,\n",
      "        e.DATE_SINISTRE,\n",
      "        case when sum(case when prxname(1) like '%facultative%' then 1 else 0 end) > 0 then 'Yes' else 'No' end as garantie_facultative\n",
      "    from agg_sinistres as a\n",
      "    inner join RADHOUAN.POLICE as b\n",
      "    on a.NUM_POLICE = b.CNUMPOLIZZA\n",
      "    inner join freq_type_sinistre as c\n",
      "    on a.NUM_POLICE = c.NUM_POLICE\n",
      "    inner join pol_count as d\n",
      "    on a.NUM_POLICE = d.NUM_POLICE\n",
      "    inner join vs22 as e\n",
      "    on a.NUM_POLICE = e.NUM_POLICE\n",
      "    group by a.NUM_POLICE,b.MARQUE_VEHICULE,b.MODELE_VEHICULE,a.nbr_sinistres,a.total_reglements,c.TYPE_SINISTRE,a.nbr_sinistres / d.nbr_police,e.DATE_DECLARATION,e.DATE_SINISTRE;\n",
      "    \n",
      "    \n",
      "    select * from joined_data;\n",
      "quit;\n",
      "```\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:56,467 - INFO - Evaluating solution for question: \n",
      "La liste des véhicules ayant enregistré une forte sinistralité au cours des 5 dernières années (Volet MAT) :\n",
      "\n",
      "-\tLe nbre = 5 sinistres \n",
      "-\tLe coût total : 10000dt\n",
      " \n",
      "Les critères que nous aimerions inclure sont les suivants :\n",
      "                                                                                                                                                                                                                                             \n",
      "•\tMarque et modèle du véhicule\n",
      "•\tNombre total de sinistres déclarés par véhicule\n",
      "•\tMontant total des indemnités versées\n",
      "•\tTypes de sinistres les plus fréquents\n",
      "•\tLa S/P\n",
      "•\tAvec les autres critères habituels du tableau (date déclaration- date sinistre – garantie facultative si existe……)\n",
      "    \n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:56,468 - INFO - Executing SAS code...\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:56,974 - INFO - SAS code executed. Returning log.\n",
      "-------------------------------------------\n",
      "2024-12-25 12:31:56,975 - INFO - Getting error reflection...\n",
      "-------------------------------------------\n",
      "2024-12-25 12:32:01,007 - INFO - Error reflection: Error Count: 4, Error Log: 666      !  then 0 else coalesce(REGLEMENT_INVENTAIRE,0) + coalesce(REGLEMENT_EXTRA_2,0) + coalesce(REGLEMENT_EXTRA,0) end) as\n",
      "666      ! REGLEMENTS_TOTALS,\n",
      "NOTE: Valeur date incorrecte\n",
      "NOTE: Invalid argument to function INPUT. Missing values may be generated.\n",
      "NOTE: Valeur date incorrecte\n",
      "NOTE: Invalid argument to function INPUT. Missing values may be generated.\n",
      "690            qualify row_number() over (partition by NUM_POLICE order by count_type desc) = 1;\n",
      "               _______\n",
      "               22\n",
      "               76\n",
      "ERROR 22-322: Erreur de syntaxe, l'une des valeurs suivantes est attendue : ;, !, !!, &, (, *, **, +, ',', -, '.', /, <, <=, <>, =, \n",
      "              >, >=, ?, AND, BETWEEN, CONTAINS, EQ, EQT, EXCEPT, GE, GET, GT, GTT, HAVING, IN, INTERSECT, IS, LE, LET, LIKE, LT, \n",
      "              LTT, NE, NET, NOT, NOTIN, OR, ORDER, OUTER, UNION, ^, ^=, |, ||, ~, ~=.\n",
      "\n",
      "ERROR 76-322: Syntax error, statement will be ignored.\n",
      "\n",
      "NOTE: PROC SQL set option NOEXEC and will continue to check the syntax of statements.\n",
      "710      ! garantie_facultative\n",
      "720      ! a.NUM_POLICE,b.MARQUE_VEHICULE,b.MODELE_VEHICULE,a.nbr_sinistres,a.total_reglements,c.TYPE_SINISTRE,a.nbr_sinistres /\n",
      "720      ! d.nbr_police,e.DATE_DECLARATION,e.DATE_SINISTRE;\n",
      "ERROR: File WORK.JOINED_DATA.DATA does not exist., Error Category: syntax\n",
      "-------------------------------------------\n",
      "2024-12-25 12:32:01,008 - INFO - Getting requirement reflection...\n",
      "-------------------------------------------\n",
      "2024-12-25 12:32:01,225 - WARNING - Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 Resource has been exhausted (e.g. check quota)..\n",
      "-------------------------------------------\n",
      "2024-12-25 12:32:03,451 - ERROR - Error during requirement reflection generation : 429 Resource has been exhausted (e.g. check quota).\n",
      "-------------------------------------------\n",
      "2024-12-25 12:32:03,455 - ERROR - Error during reflections generation : 429 Resource has been exhausted (e.g. check quota).\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "ename": "ResourceExhausted",
     "evalue": "429 Resource has been exhausted (e.g. check quota).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhausted\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 59\u001b[0m\n\u001b[0;32m     56\u001b[0m         logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo solution found within the search limits.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 59\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[21], line 41\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Main loop\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m should_continue(state) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexpand\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 41\u001b[0m     state \u001b[38;5;241m=\u001b[39m expand_tree(state, llm, client, necessary_metadata, config)\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# Find the best solution\u001b[39;00m\n\u001b[0;32m     44\u001b[0m best_solution_node \u001b[38;5;241m=\u001b[39m state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mroot\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget_best_solution()\n",
      "Cell \u001b[1;32mIn[12], line 48\u001b[0m, in \u001b[0;36mexpand_tree\u001b[1;34m(state, llm, client, necessary_metadata, config, max_depth)\u001b[0m\n\u001b[0;32m     46\u001b[0m solution \u001b[38;5;241m=\u001b[39m solver\u001b[38;5;241m.\u001b[39mgenerate_solution(question, current_node\u001b[38;5;241m.\u001b[39mstrategy)\n\u001b[0;32m     47\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating solution: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msolution\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 48\u001b[0m evaluation, critic_score, feedback \u001b[38;5;241m=\u001b[39m critic\u001b[38;5;241m.\u001b[39mevaluate_solution(question, solution, current_node\u001b[38;5;241m.\u001b[39mstrategy)\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Update current node and create a new node\u001b[39;00m\n\u001b[0;32m     51\u001b[0m current_node\u001b[38;5;241m.\u001b[39msolution \u001b[38;5;241m=\u001b[39m solution\n",
      "Cell \u001b[1;32mIn[19], line 230\u001b[0m, in \u001b[0;36mCritic.evaluate_solution\u001b[1;34m(self, question, solution, strategy)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    229\u001b[0m     error_reflection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_error_reflection(question, solution, log)\n\u001b[1;32m--> 230\u001b[0m     requirement_reflection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_requirement_reflection(question, solution, log)\n\u001b[0;32m    231\u001b[0m     strategy_adherence_reflection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_strategy_adherence_reflection(question, solution, strategy)\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "Cell \u001b[1;32mIn[19], line 378\u001b[0m, in \u001b[0;36mCritic._get_requirement_reflection\u001b[1;34m(self, query, sas_code, log)\u001b[0m\n\u001b[0;32m    361\u001b[0m prompt \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_messages([\n\u001b[0;32m    362\u001b[0m     (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msystem\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    363\u001b[0m \u001b[38;5;124m    You are a helpful assistant that identifies missing requirements in SAS code.\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[0;32m    376\u001b[0m ])\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     response \u001b[38;5;241m=\u001b[39m (prompt \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm \u001b[38;5;241m|\u001b[39m parser)\u001b[38;5;241m.\u001b[39minvoke({\n\u001b[0;32m    379\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: query,\n\u001b[0;32m    380\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msas_code\u001b[39m\u001b[38;5;124m\"\u001b[39m: sas_code,\n\u001b[0;32m    381\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnecessary_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnecessary_metadata,\n\u001b[0;32m    382\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat_instructions\u001b[39m\u001b[38;5;124m\"\u001b[39m: parser\u001b[38;5;241m.\u001b[39mget_format_instructions()\n\u001b[0;32m    383\u001b[0m     })\n\u001b[0;32m    384\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m    385\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRequirement reflection: Missing Requirements: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mmissing_requirements\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Requirements Met: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mrequirements_met\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3024\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3022\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3023\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3024\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n\u001b[0;32m   3025\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3026\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:286\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    276\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    277\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    281\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    282\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    283\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    285\u001b[0m         ChatGeneration,\n\u001b[1;32m--> 286\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    287\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    288\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    289\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    290\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    291\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    292\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    293\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    294\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    295\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    296\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:786\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    780\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    784\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    785\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 786\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:643\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[0;32m    642\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[1;32m--> 643\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    644\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    645\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[0;32m    646\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[0;32m    647\u001b[0m ]\n\u001b[0;32m    648\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:633\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[0;32m    631\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    632\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 633\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    634\u001b[0m                 m,\n\u001b[0;32m    635\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    636\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    637\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    638\u001b[0m             )\n\u001b[0;32m    639\u001b[0m         )\n\u001b[0;32m    640\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    641\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:851\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    850\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 851\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m    852\u001b[0m             messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    853\u001b[0m         )\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    855\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:946\u001b[0m, in \u001b[0;36mChatGoogleGenerativeAI._generate\u001b[1;34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[0m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate\u001b[39m(\n\u001b[0;32m    921\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    922\u001b[0m     messages: List[BaseMessage],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    933\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    934\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResult:\n\u001b[0;32m    935\u001b[0m     request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_request(\n\u001b[0;32m    936\u001b[0m         messages,\n\u001b[0;32m    937\u001b[0m         stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m         tool_choice\u001b[38;5;241m=\u001b[39mtool_choice,\n\u001b[0;32m    945\u001b[0m     )\n\u001b[1;32m--> 946\u001b[0m     response: GenerateContentResponse \u001b[38;5;241m=\u001b[39m _chat_with_retry(\n\u001b[0;32m    947\u001b[0m         request\u001b[38;5;241m=\u001b[39mrequest,\n\u001b[0;32m    948\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    949\u001b[0m         generation_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mgenerate_content,\n\u001b[0;32m    950\u001b[0m         metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_metadata,\n\u001b[0;32m    951\u001b[0m     )\n\u001b[0;32m    952\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:196\u001b[0m, in \u001b[0;36m_chat_with_retry\u001b[1;34m(generation_method, **kwargs)\u001b[0m\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    194\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m--> 196\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _chat_with_retry(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tenacity\\__init__.py:336\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    334\u001b[0m copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    335\u001b[0m wrapped_f\u001b[38;5;241m.\u001b[39mstatistics \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mstatistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m--> 336\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m copy(f, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tenacity\\__init__.py:475\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    473\u001b[0m retry_state \u001b[38;5;241m=\u001b[39m RetryCallState(retry_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, fn\u001b[38;5;241m=\u001b[39mfn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m    474\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 475\u001b[0m     do \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter(retry_state\u001b[38;5;241m=\u001b[39mretry_state)\n\u001b[0;32m    476\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    477\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tenacity\\__init__.py:376\u001b[0m, in \u001b[0;36mBaseRetrying.iter\u001b[1;34m(self, retry_state)\u001b[0m\n\u001b[0;32m    374\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_state\u001b[38;5;241m.\u001b[39mactions:\n\u001b[1;32m--> 376\u001b[0m     result \u001b[38;5;241m=\u001b[39m action(retry_state)\n\u001b[0;32m    377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tenacity\\__init__.py:418\u001b[0m, in \u001b[0;36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[1;34m(rs)\u001b[0m\n\u001b[0;32m    416\u001b[0m retry_exc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_error_cls(fut)\n\u001b[0;32m    417\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreraise:\n\u001b[1;32m--> 418\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m retry_exc\u001b[38;5;241m.\u001b[39mreraise()\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mfut\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexception\u001b[39;00m()\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tenacity\\__init__.py:185\u001b[0m, in \u001b[0;36mRetryError.reraise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m t\u001b[38;5;241m.\u001b[39mNoReturn:\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mfailed:\n\u001b[1;32m--> 185\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_attempt\u001b[38;5;241m.\u001b[39mresult()\n\u001b[0;32m    186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\concurrent\\futures\\_base.py:449\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 449\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m    451\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_condition\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    399\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    400\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 401\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    402\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    404\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tenacity\\__init__.py:478\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 478\u001b[0m         result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[0;32m    480\u001b[0m         retry_state\u001b[38;5;241m.\u001b[39mset_exception(sys\u001b[38;5;241m.\u001b[39mexc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:194\u001b[0m, in \u001b[0;36m_chat_with_retry.<locals>._chat_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid argument provided to Gemini: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    192\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 194\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:178\u001b[0m, in \u001b[0;36m_chat_with_retry.<locals>._chat_with_retry\u001b[1;34m(**kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_chat_with_retry\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 178\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_method(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    179\u001b[0m     \u001b[38;5;66;03m# Do not retry for these errors.\u001b[39;00m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mFailedPrecondition \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:830\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[1;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[0;32m    829\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m--> 830\u001b[0m response \u001b[38;5;241m=\u001b[39m rpc(\n\u001b[0;32m    831\u001b[0m     request,\n\u001b[0;32m    832\u001b[0m     retry\u001b[38;5;241m=\u001b[39mretry,\n\u001b[0;32m    833\u001b[0m     timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m    834\u001b[0m     metadata\u001b[38;5;241m=\u001b[39mmetadata,\n\u001b[0;32m    835\u001b[0m )\n\u001b[0;32m    837\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wrapped_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    292\u001b[0m )\n\u001b[1;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m retry_target(\n\u001b[0;32m    294\u001b[0m     target,\n\u001b[0;32m    295\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_predicate,\n\u001b[0;32m    296\u001b[0m     sleep_generator,\n\u001b[0;32m    297\u001b[0m     timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout,\n\u001b[0;32m    298\u001b[0m     on_error\u001b[38;5;241m=\u001b[39mon_error,\n\u001b[0;32m    299\u001b[0m )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m     _retry_error_helper(\n\u001b[0;32m    154\u001b[0m         exc,\n\u001b[0;32m    155\u001b[0m         deadline,\n\u001b[0;32m    156\u001b[0m         sleep,\n\u001b[0;32m    157\u001b[0m         error_list,\n\u001b[0;32m    158\u001b[0m         predicate,\n\u001b[0;32m    159\u001b[0m         on_error,\n\u001b[0;32m    160\u001b[0m         exception_factory,\n\u001b[0;32m    161\u001b[0m         timeout,\n\u001b[0;32m    162\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\google\\api_core\\retry\\retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[1;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[0;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[0;32m    208\u001b[0m         error_list,\n\u001b[0;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[0;32m    210\u001b[0m         original_timeout,\n\u001b[0;32m    211\u001b[0m     )\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m target()\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\google\\api_core\\timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mResourceExhausted\u001b[0m: 429 Resource has been exhausted (e.g. check quota)."
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Initialize configuration (tune these parameters)\n",
    "    config = {\n",
    "        \"execution_weight\": 0.6,\n",
    "        \"critic_weight\": 0.4,\n",
    "        \"error_weight\": 0.2,\n",
    "        \"requirement_weight\": 0.3,\n",
    "        \"verification_fail_score\": 0.5,\n",
    "        \"abort_threshold\": 0.4,\n",
    "        \"expansion_threshold\": 0.6\n",
    "    }\n",
    "    # Example query\n",
    "    query = \"\"\"\n",
    "La liste des véhicules ayant enregistré une forte sinistralité au cours des 5 dernières années (Volet MAT) :\n",
    "\n",
    "-\tLe nbre = 5 sinistres \n",
    "-\tLe coût total : 10000dt\n",
    " \n",
    "Les critères que nous aimerions inclure sont les suivants :\n",
    "                                                                                                                                                                                                                                             \n",
    "•\tMarque et modèle du véhicule\n",
    "•\tNombre total de sinistres déclarés par véhicule\n",
    "•\tMontant total des indemnités versées\n",
    "•\tTypes de sinistres les plus fréquents\n",
    "•\tLa S/P\n",
    "•\tAvec les autres critères habituels du tableau (date déclaration- date sinistre – garantie facultative si existe……)\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize LLM and necessary metadata\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-exp\", convert_system_message_to_human=True)\n",
    "    # Mocking the client for testing purposes, replace with actual client if needed\n",
    "    client = Client(\"Qwen/Qwen2.5-Coder-Artifacts\")\n",
    "    necessary_metadata = CachedMetadata.get_instance(metadata_dict, query)._metadata\n",
    "\n",
    "    # Initialize the tree state\n",
    "    state = {\"input\": query}\n",
    "    state = generate_initial_strategies(state, llm, necessary_metadata, config)\n",
    "\n",
    "    # Main loop\n",
    "    while should_continue(state) == \"expand\":\n",
    "        state = expand_tree(state, llm, client, necessary_metadata, config)\n",
    "\n",
    "    # Find the best solution\n",
    "    best_solution_node = state[\"root\"].get_best_solution()\n",
    "\n",
    "    if best_solution_node:\n",
    "        logging.info(f\"Best solution found:\\n{best_solution_node.solution}\")\n",
    "        if best_solution_node.evaluation == \"Accept\":\n",
    "            logging.info(\"Solution was accepted by the Critic.\")\n",
    "        else:\n",
    "            logging.info(\"Solution was not accepted, but it's the best found within the search limits.\")\n",
    "\n",
    "        # Extract data if needed\n",
    "        extract_data(best_solution_node.solution,client)\n",
    "    else:\n",
    "        logging.info(\"No solution found within the search limits.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
